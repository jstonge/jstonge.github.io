[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html",
    "href": "posts/sci-group-life-cycle/index.html",
    "title": "Scientific group life cycle",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThere are research groups \\(G\\) with a number of non-programmers \\(n\\) and programmers \\(p\\). In a data-driven world, we assume that learning to code confer a large benefit to programmers over non-programmer such that \\(\\alpha << \\beta\\). There is a constant rate of influx of students who do not know how to learn to code in research groups \\(\\mu\\). There is a cost of learning to code \\(c(p,n)\\), which depend on the number of programmers and non-programmers within group. We assume that programmers and non-programmers have different graduation rates, \\(\\nu_p\\) and \\(\\nu_n\\), with \\(\\nu_p > \\nu_n\\).\nWe model the group life cycle with the following master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{n,p} &= \\mu(G_{n-1,p} - G_{n,p}) + \\nu_n \\Big((n+1)G_{n+1,p}-nG_{n,p}\\Big) \\\\\n                           &+ \\Big[ \\tau_g(n+1,p-1)(1-c(n+1, p-1)G_{n+1,p-1} - \\tau_g(n,p)G_{n,p} \\Big] \\\\\n                   &+ \\nu_p\\Big((p+1)G_{n,p+1} - pG_{n,p} \\Big) \\\\\n                   &+ \\tau_g(n+1,p)(1-c(n+1,p))G_{n+1,p}\n\\end{align*}\\]\nLearning to code confers a collective benefits on individuals \\(\\tau_g(n,p; \\alpha, \\beta) \\propto \\frac{\\bar{Z}_{n,p}}{Z_{n,p}}\\), where\n\\[\\log(Z_{n,p}) \\sim \\alpha * n + \\beta * p\\] \\[\\log(\\bar{Z}_{n,p}) \\sim \\alpha (n-1) +\\beta (c * p + (1-c)(p+1))\\]\nWe can think of \\(\\bar{Z}_{n,p}\\) as the potential benefits over \\(Z_{n,p}\\). Reorganizing the terms, we get:\n\\[\\begin{align*}\n\\log[\\tau_g(n,p; \\alpha, \\beta))] &= \\alpha (n-1) +\\beta (c * p + (1-c)(p+1)) - \\alpha * n + \\beta * p \\\\\n                                  &= -\\alpha + \\beta(1-c)\n\\end{align*}\\]\nNote that \\(\\tau_g\\) ends up being a function of \\(n, p\\) through the cost function: \\[c(n,p) = c_0*e^{-\\frac{p}{n}}\\]\nYou can explore both functions below:\n\n\n\n\n\n\nCost function\n\n\n\n\n\n\n\nfunction cost_prog(n, i, c_0) { return c_0 * Math.exp(-i/n); }\nfunction cost_prog2(n, i, c_0) { return c_0 * Math.exp(-i/(n+i)); }\n\nmax_gr_size = 20\nviewof N = Inputs.range([1, max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof coder = Inputs.range([0, (N-1)], {value: 10, step: 1, label: \"# coder\"})\nviewof c_0 = Inputs.range([0, 1], {value: 0.95, step: 0.01, label: \"c₀\"})\nviewof nc = Inputs.range([1, N], {value: (N-coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc(n,p) = c₀ * exp(-p/n)c(n,p) = c₀ * exp(-p/(n+p))\n\n\n\nnon_coder = N - coder\nxs = [...Array(N).keys()];\nys = xs.map(x => cost_prog(non_coder, x, c_0))\n\n\nPlot.lineY(ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\nx2s = [...Array(N).keys()];\ny2s = x2s.map(x => cost_prog2(non_coder, x, c_0))\n\nPlot.lineY(y2s).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup benefits\n\n\n\n\n\n\n\nfunction tau(n, i, alpha, beta) {\n    const c = cost_prog(n, i, 1)\n    return Math.exp(-alpha + beta*(1 - c))\n}\n\ntau_max_gr_size = 20\nviewof tau_alpha = Inputs.range([2, 4], {value: 1., step: 1, label: \"α\", format: x => 10**-x})\nviewof tau_beta = Inputs.range([1, 3], {value: 1., step: 1, label: \"β\", format: x => 10**-x})\nviewof tau_N = Inputs.range([0, tau_max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof tau_coder = Inputs.range([1, tau_max_gr_size], {value: 10, step: 1, label: \"# coder\"})\nviewof tau_nc = Inputs.range([1, max_gr_size], {value: (tau_N-tau_coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nτ(n,p) 1\n\n\n\ntau_non_coder = tau_N - tau_coder\ntau_xs = [...Array(tau_N).keys()];\ntau_ys = tau_xs.map(x => tau(tau_non_coder, x, 10**-tau_alpha, 10**-tau_beta))\n\nPlot.lineY(tau_ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ τ(α,β;n,p)\" },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  ="
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#julia-model",
    "href": "posts/sci-group-life-cycle/index.html#julia-model",
    "title": "Scientific group life cycle",
    "section": "Julia model",
    "text": "Julia model\n\n\n\n\n\n\nInitialization scheme\n\n\n\n\n\nfunction initialize_u0(;N::Int=20)\n  N += 1 # add column for zeroth case\n  G = zeros(N, N)\n  \n  for i=1:N, j=1:N\n    G[i,j] = 1/(N*N)\n  end\n  return ArrayPartition(Tuple([G[n,:] for n=1:N]))\nend\n\nμ  = 0.001   # inflow new students-non coders\nνₙ = 0.01    # death rate non-coders\nνₚ = 0.05    # death rate coders\nα  = 0.01    # benefits non coders\nβ  = 0.1     # benefits coders\np  = [μ, νₙ, νₚ, α, β]\n\nn = 9\nu₀ = initialize_u0(N=n)\ntspan = (0., 1000.)\n\n\n\nc(n, i) = 0.95 * exp(-i / n) # cost function\nτ(n, i, α, β) = exp(-α + β*(1 - c(n, i))) # group benefits\n\nfunction life_cycle_research_groups!(du, u, p, t)\n\n  G, N, P = u, length(u.x), length(first(u₀.x)) # Note that there can be no coders but not non-coders\n  μ, νₙ, νₚ, α, β = p\n  for n=1:N, i=1:P\n    println(\"n:$(n), i:$(i), G.x[n][i]:$(G.x[n][i])\")\n    coder, non_coder = i-1, n-1   # we distinguish indices from actual values.\n    \n    du.x[n][i] = 0\n\n    non_coder > 0 && ( du.x[n][i] += μ*(G.x[n-1][i]) )                # 1st term\n    \n    # for everybody\n    # println(\"2: $(νₙ*non_coder*G.x[n][i])\")\n    du.x[n][i] -= νₙ*non_coder*G.x[n][i]\n    # println(\"3: $(νₚ*coder*G.x[n][i])\")\n    du.x[n][i] -= νₚ*coder*G.x[n][i]\n\n    # upper boxes don't exist \n    if i < P\n      # non_coder > 0 && println(\"4: $(τ(non_coder, coder, α, β)*G.x[n][i] )\")\n      # We don't want to pass non_coder = 0 to τ()\n      non_coder > 0 && ( du.x[n][i] -= τ(non_coder, coder, α, β)*G.x[n][i] )               # 4th term\n      # println(\"5: $(νₚ*(coder+1)*G.x[n][i+1])\")\n      du.x[n][i] += νₚ*(coder+1)*G.x[n][i+1]  # 5th term\n    end\n    \n    # the bottom boxes don't exist\n    if n < N\n      # println(\"6: $(μ*G.x[n][i])\")\n      du.x[n][i] -= μ*G.x[n][i]                                       # 1st term\n      du.x[n][i] += τ(non_coder+1, coder, α, β)*(c(non_coder+1, coder))*G.x[n+1][i]     # 6th term\n      du.x[n][i] += νₙ*(non_coder+1)*G.x[n+1][i]                                            # 2nd term\n      coder > 0 && ( du.x[n][i] += τ(non_coder+1, coder-1, α, β)*(1-c(non_coder+1, coder-1))*G.x[n+1][i-1] ) # 3rd term \n    end\n  end\nend"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#output",
    "href": "posts/sci-group-life-cycle/index.html#output",
    "title": "Scientific group life cycle",
    "section": "Output",
    "text": "Output\n\ndata = FileAttachment(\"data.json\").json()\np = Object.keys(data).map(d => d.split(\"_\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\n\nviewof N_    = Inputs.range(minmax(p,0), {step: 1, label: \"N\", value:\"4\"})\nviewof mu    = Inputs.range(minmax(p,1), {step: 0.03, label: \"μ\", value:\"0.0001\"})\nviewof nu_n  = Inputs.range(minmax(p,2), {step: 0.05, label: \"νₙ\", value:\"0.01\"})\nviewof nu_p  = Inputs.range(minmax(p,3), {step: 0.1,  label: \"νₚ\", value:\"0.05\"})\nviewof alpha = Inputs.range(minmax(p,4), {step: 0.15, label: \"α\", value:\"0.01\"})\nviewof beta  = Inputs.range(minmax(p,5), {step: 0.05, label: \"β\", value:\"0.1\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\n\n\n\nf = (x) => x.toPrecision() ? x.toPrecision(2) : x\n\nPlot.plot({\n  x: {type:\"log\"},\n  y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        }),\n    Plot.dot(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        })\n  ]\n})"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#takeaways",
    "href": "posts/sci-group-life-cycle/index.html#takeaways",
    "title": "Scientific group life cycle",
    "section": "Takeaways:",
    "text": "Takeaways:"
  },
  {
    "objectID": "posts/source-sink/index.html",
    "href": "posts/source-sink/index.html",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThe key ingredients of the model are our groups \\(G\\) with the number of adopters \\(i\\) and with an institution of level \\(\\ell\\). We assume that with higher levels of institutional strength, \\(\\ell\\), the institution will more effectively promote group-beneficial behavior, \\(\\ell\\)\\(\\beta\\). As it gets better, each adopter in the group also gain a collective benefit \\(b\\). But all of these toodily-doo perks are offset by an institutional implementation costs, \\(c\\), of entertaining larger groups. For instance, think of the process of unionization, promoting behaviors that are costly at individual level. When unionization becomes more successful, the unions can become ungaingly. Lastly adopters lose their behavioural trait at a rate \\(\\gamma\\).\nFirst master equation1:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{diff} &= \\ell \\mathbin{\\color{darkgreen}{\\beta}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\ell\\mathbin{\\color{darkgreen}{\\beta}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\mathbin{\\color{red}{\\gamma}}(i+1)G_{i+1,\\ell} - \\mathbin{\\color{red}{\\gamma}} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\color{blue}{\\rho}} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\nSecond master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{select} &= \\mathbin{\\color{blue}{\\rho}} [G_{i,\\ell-1}(Z_\\ell Z_{\\ell-1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}}) + G_{i,\\ell+1}(Z\\ell Z_{\\ell + 1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}})] \\\\\n                                &-\\mathbin{\\color{blue}{\\rho}}(Z_{\\ell-1}Z_\\ell^{-1} + Z_{\\ell+1}^{-1} + 2\\mathbin{\\color{midnightblue}{\\mu}})G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(Z_\\ell = \\frac{\\sum_{i'} exp(\\mathbin{\\color{seagreen}{b}}i'- \\mathbin{\\color{darkred}{c}}\\ell)G_{i',\\ell}}{\\sum_{i'}G_{i',\\ell}}\\). Note that we add a constant rate of transition \\(\\mu\\) to the selection proces.\nTaken togetherm we have the set of master equations:\n\\[\n\\frac{d}{dt}G_{i,\\ell} = \\frac{d}{dt}G_{i,\\ell}^{diff} + \\frac{d}{dt}G_{i,\\ell}^{select}\n\\]\n\nModel 1Model 2\n\n\nfunction source_sink!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n      n_adopt = collect(0:(n-1))\n      Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])\n      pop[ℓ]  = sum(G.x[ℓ])\n      R       += sum(ρ*n_adopt .* G.x[ℓ])\n      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )\n    end\n\n    for ℓ = 1:L, i = 1:n\n      n_adopt, gr_size = i-1, n-1\n\n      # Diffusion events\n      du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - (ℓ-1)*β*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n\n      n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ-1)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n      n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n\n      # Group selection process\n      ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n      ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n    end\nend\n\n\nfunction source_sink2!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, α, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n        n_adopt = collect(0:(n-1))\n        Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ]) \n        pop[ℓ]  = sum(G.x[ℓ])\n        R      += sum(ρ * n_adopt .* G.x[ℓ]) \n        pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] ) \n      end\n      \n      for ℓ = 1:L, i = 1:n\n        n_adopt, gr_size = i-1, n-1\n        # Diffusion events\n        du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - β*(ℓ^-α)*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n        n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ^-α)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n        n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n        # Group selection process\n        ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n        ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n      end\nend\n\n\n\n\nresdb = FileAttachment(\"source-sink-res.db\").sqlite()\n\n\n\n\n\n\n\nf = (x) => Number.isInteger(x) ? x.toPrecision(2) : x\nminmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\ns = (p,i) => { \n  const unique_vals = Array.from(new Set(p.map(d => parseFloat(d[i]))))\n                           .sort((a,b) => a - b)\n  const out = []\n  for (let i=1; i < unique_vals.length; i++ ) {\n    out.push(+(unique_vals[i]-unique_vals[i-1]).toPrecision(1))\n  } // return whatev if length is zero\n  return out.length === 0 ? 0.1 : out[0]\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot 1Plot 2\n\n\n\n\nunique_name = resdb.query(`SELECT DISTINCT name FROM sourcesink1`)\np = unique_name.map(d => d.name.split(\"_\"))\n\nviewof beta  = Inputs.range(minmax(p,0), {step: s(p,0),  label: \"β\", value:p[0][0]})\nviewof gamma = Inputs.range(minmax(p,1), {step: s(p,1),  label: \"γ\", value:p[0][1]})\nviewof rho   = Inputs.range(minmax(p,2), {step: s(p,2),  label: \"ρ\", value:p[0][2]})\nviewof b     = Inputs.range(minmax(p,3), {step: s(p,3),  label: \"b\", value:p[0][3]})\nviewof c     = Inputs.range(minmax(p,4), {step: s(p,4),  label: \"c\", value:p[0][4]})\nviewof mu    = Inputs.range(minmax(p,5), {step: s(p,5),  label: \"μ\", value:p[0][5]})\n\ndata = resdb.query(`\n  SELECT * \n  FROM sourcesink1\n  WHERE\n  name = '${f(beta)}_${f(gamma)}_${f(rho)}_${f(b)}_${f(c)}_${f(mu)}'\n`)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot.plot({\n  x: {type:\"log\"},\n  // y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data, {\n        x: 'timestep', y: \"value\", stroke: \"L\"\n        }),\n    Plot.dot(\n      data, {\n        x: 'timestep', y: \"value\", stroke: \"L\"\n        })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency of behaviour in groups with different institutional strength.\nWithin groups, the frequency of cooperative behaviour follows the strength of institutions (with ℓ = 1 in light beige and ℓ = 6 in dark red).\nQualitatively, no institutions are possible if institutional costs are too high, and the behaviour never spreads.\nThe time dynamics of global behavioural frequency and behaviour in groups can include patterns of surge and collapse.\n\n\n\n\n\n\nunique_name2 = resdb.query(`SELECT DISTINCT name FROM sourcesink2`)\np2 = unique_name.map(d => d.name.split(\"_\"))\n\nviewof beta2  = Inputs.range(minmax(p2,0), {step: s(p2,0),  label: \"β\", value:p2[0][0]})\nviewof alpha  = Inputs.range(minmax(p2,1), {step: s(p2,1),  label: \"α\", value:p2[0][1]})\nviewof gamma2 = Inputs.range(minmax(p2,2), {step: s(p2,2),  label: \"γ\", value:p2[0][2]})\nviewof rho2   = Inputs.range(minmax(p2,3), {step: s(p2,3),  label: \"ρ\", value:p2[0][3]})\nviewof b2     = Inputs.range(minmax(p2,4), {step: s(p2,4),  label: \"b\", value:p2[0][4]})\nviewof c2     = Inputs.range(minmax(p2,5), {step: s(p2,5),  label: \"c\", value:p2[0][5]})\nviewof mu2    = Inputs.range(minmax(p2,6), {step: s(p2,6),  label: \"μ\", value:p2[0][6]})\n\n// use sql query to filter\ndata2 = resdb.query(`\n  SELECT * \n  FROM sourcesink2\n  WHERE\n  name = '${f(beta2)}_${f(alpha)}_${f(gamma2)}_${f(rho2)}_${f(b2)}_${f(c2)}_${f(mu2)}'\n`)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot.plot({\n  x: {type:\"log\"},\n  // y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data2, {\n        x: 'timestep', y: \"value\", stroke: \"L\"\n        }),\n    Plot.dot(\n      data2, {\n        x: 'timestep', y: \"value\", stroke: \"L\"\n        })\n  ]\n})"
  }
]