[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html",
    "href": "posts/sci-group-life-cycle/index.html",
    "title": "Scientific group life cycle",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThere are research groups \\(G\\) with a number of non-programmers \\(n\\) and programmers \\(p\\). In a data-driven world, we assume that learning to code confer a large benefit to programmers over non-programmer such that \\(\\alpha &lt;&lt; \\beta\\). There is a constant rate of influx of students who do not know how to learn to code in research groups \\(\\mu\\). There is a cost of learning to code \\(c(p,n)\\), which depend on the number of programmers and non-programmers within group. We assume that programmers and non-programmers have different graduation rates, \\(\\nu_p\\) and \\(\\nu_n\\), with \\(\\nu_p &gt; \\nu_n\\).\nWe model the group life cycle with the following master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{n,p} &= \\mu(G_{n-1,p} - G_{n,p}) + \\nu_n \\Big((n+1)G_{n+1,p}-nG_{n,p}\\Big) \\\\\n                           &+ \\Big[ \\tau_g(n+1,p-1)(1-c(n+1, p-1)G_{n+1,p-1} - \\tau_g(n,p)G_{n,p} \\Big] \\\\\n                   &+ \\nu_p\\Big((p+1)G_{n,p+1} - pG_{n,p} \\Big) \\\\\n                   &+ \\tau_g(n+1,p)(1-c(n+1,p))G_{n+1,p}\n\\end{align*}\\]\nLearning to code confers a collective benefits on individuals \\(\\tau_g(n,p; \\alpha, \\beta) \\propto \\frac{\\bar{Z}_{n,p}}{Z_{n,p}}\\), where\n\\[\\log(Z_{n,p}) \\sim \\alpha * n + \\beta * p\\] \\[\\log(\\bar{Z}_{n,p}) \\sim \\alpha (n-1) +\\beta (c * p + (1-c)(p+1))\\]\nWe can think of \\(\\bar{Z}_{n,p}\\) as the potential benefits over \\(Z_{n,p}\\). Reorganizing the terms, we get:\n\\[\\begin{align*}\n\\log[\\tau_g(n,p; \\alpha, \\beta))] &= \\alpha (n-1) +\\beta (c * p + (1-c)(p+1)) - \\alpha * n + \\beta * p \\\\\n                                  &= -\\alpha + \\beta(1-c)\n\\end{align*}\\]\nNote that \\(\\tau_g\\) ends up being a function of \\(n, p\\) through the cost function: \\[c(n,p) = c_0*e^{-\\frac{p}{n}}\\]\nYou can explore both functions below:\n\n\n\n\n\n\nCost function\n\n\n\n\n\n\nfunction cost_prog(n, i, c_0) { return c_0 * Math.exp(-i/n); }\nfunction cost_prog2(n, i, c_0) { return c_0 * Math.exp(-i/(n+i)); }\n\nmax_gr_size = 20\nviewof N = Inputs.range([1, max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof coder = Inputs.range([0, (N-1)], {value: 10, step: 1, label: \"# coder\"})\nviewof c_0 = Inputs.range([0, 1], {value: 0.95, step: 0.01, label: \"c₀\"})\nviewof nc = Inputs.range([1, N], {value: (N-coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc(n,p) = c₀ * exp(-p/n)c(n,p) = c₀ * exp(-p/(n+p))\n\n\n\nnon_coder = N - coder\nxs = [...Array(N).keys()];\nys = xs.map(x =&gt; cost_prog(non_coder, x, c_0))\n\n\nPlot.lineY(ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\nx2s = [...Array(N).keys()];\ny2s = x2s.map(x =&gt; cost_prog2(non_coder, x, c_0))\n\nPlot.lineY(y2s).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\n\n\n\n\n\n\n\n\n\nGroup benefits\n\n\n\n\n\n\nfunction tau(n, i, alpha, beta) {\n    const c = cost_prog(n, i, 1)\n    return Math.exp(-alpha + beta*(1 - c))\n}\n\ntau_max_gr_size = 20\nviewof tau_alpha = Inputs.range([2, 4], {value: 1., step: 1, label: \"α\", format: x =&gt; 10**-x})\nviewof tau_beta = Inputs.range([1, 3], {value: 1., step: 1, label: \"β\", format: x =&gt; 10**-x})\nviewof tau_N = Inputs.range([0, tau_max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof tau_coder = Inputs.range([1, tau_max_gr_size], {value: 10, step: 1, label: \"# coder\"})\nviewof tau_nc = Inputs.range([1, max_gr_size], {value: (tau_N-tau_coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nτ(n,p) 1\n\n\n\ntau_non_coder = tau_N - tau_coder\ntau_xs = [...Array(tau_N).keys()];\ntau_ys = tau_xs.map(x =&gt; tau(tau_non_coder, x, 10**-tau_alpha, 10**-tau_beta))\n\nPlot.lineY(tau_ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ τ(α,β;n,p)\" },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  ="
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#julia-model",
    "href": "posts/sci-group-life-cycle/index.html#julia-model",
    "title": "Scientific group life cycle",
    "section": "Julia model",
    "text": "Julia model\n\n\n\n\n\n\nInitialization scheme\n\n\n\n\n\nfunction initialize_u0(;N::Int=20)\n  N += 1 # add column for zeroth case\n  G = zeros(N, N)\n  \n  for i=1:N, j=1:N\n    G[i,j] = 1/(N*N)\n  end\n  return ArrayPartition(Tuple([G[n,:] for n=1:N]))\nend\n\nμ  = 0.001   # inflow new students-non coders\nνₙ = 0.01    # death rate non-coders\nνₚ = 0.05    # death rate coders\nα  = 0.01    # benefits non coders\nβ  = 0.1     # benefits coders\np  = [μ, νₙ, νₚ, α, β]\n\nn = 9\nu₀ = initialize_u0(N=n)\ntspan = (0., 1000.)\n\n\n\nc(n, i) = 0.95 * exp(-i / n) # cost function\nτ(n, i, α, β) = exp(-α + β*(1 - c(n, i))) # group benefits\n\nfunction life_cycle_research_groups!(du, u, p, t)\n\n  G, N, P = u, length(u.x), length(first(u₀.x)) # Note that there can be no coders but not non-coders\n  μ, νₙ, νₚ, α, β = p\n  for n=1:N, i=1:P\n    println(\"n:$(n), i:$(i), G.x[n][i]:$(G.x[n][i])\")\n    coder, non_coder = i-1, n-1   # we distinguish indices from actual values.\n    \n    du.x[n][i] = 0\n\n    non_coder &gt; 0 && ( du.x[n][i] += μ*(G.x[n-1][i]) )                # 1st term\n    \n    # for everybody\n    # println(\"2: $(νₙ*non_coder*G.x[n][i])\")\n    du.x[n][i] -= νₙ*non_coder*G.x[n][i]\n    # println(\"3: $(νₚ*coder*G.x[n][i])\")\n    du.x[n][i] -= νₚ*coder*G.x[n][i]\n\n    # upper boxes don't exist \n    if i &lt; P\n      # non_coder &gt; 0 && println(\"4: $(τ(non_coder, coder, α, β)*G.x[n][i] )\")\n      # We don't want to pass non_coder = 0 to τ()\n      non_coder &gt; 0 && ( du.x[n][i] -= τ(non_coder, coder, α, β)*G.x[n][i] )               # 4th term\n      # println(\"5: $(νₚ*(coder+1)*G.x[n][i+1])\")\n      du.x[n][i] += νₚ*(coder+1)*G.x[n][i+1]  # 5th term\n    end\n    \n    # the bottom boxes don't exist\n    if n &lt; N\n      # println(\"6: $(μ*G.x[n][i])\")\n      du.x[n][i] -= μ*G.x[n][i]                                       # 1st term\n      du.x[n][i] += τ(non_coder+1, coder, α, β)*(c(non_coder+1, coder))*G.x[n+1][i]     # 6th term\n      du.x[n][i] += νₙ*(non_coder+1)*G.x[n+1][i]                                            # 2nd term\n      coder &gt; 0 && ( du.x[n][i] += τ(non_coder+1, coder-1, α, β)*(1-c(non_coder+1, coder-1))*G.x[n+1][i-1] ) # 3rd term \n    end\n  end\nend"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#output",
    "href": "posts/sci-group-life-cycle/index.html#output",
    "title": "Scientific group life cycle",
    "section": "Output",
    "text": "Output\n\ndata = FileAttachment(\"data.json\").json()\np = Object.keys(data).map(d =&gt; d.split(\"_\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminmax = (p, i) =&gt; d3.extent(p.map(d =&gt; parseFloat(d[i])))\n\nviewof N_    = Inputs.range(minmax(p,0), {step: 1, label: \"N\", value:\"4\"})\nviewof mu    = Inputs.range(minmax(p,1), {step: 0.03, label: \"μ\", value:\"0.0001\"})\nviewof nu_n  = Inputs.range(minmax(p,2), {step: 0.05, label: \"νₙ\", value:\"0.01\"})\nviewof nu_p  = Inputs.range(minmax(p,3), {step: 0.1,  label: \"νₚ\", value:\"0.05\"})\nviewof alpha = Inputs.range(minmax(p,4), {step: 0.15, label: \"α\", value:\"0.01\"})\nviewof beta  = Inputs.range(minmax(p,5), {step: 0.05, label: \"β\", value:\"0.1\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\n\n\n\nf = (x) =&gt; x.toPrecision() ? x.toPrecision(2) : x\n\nPlot.plot({\n  x: {type:\"log\"},\n  y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        }),\n    Plot.dot(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        })\n  ]\n})"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#takeaways",
    "href": "posts/sci-group-life-cycle/index.html#takeaways",
    "title": "Scientific group life cycle",
    "section": "Takeaways:",
    "text": "Takeaways:"
  },
  {
    "objectID": "posts/source-sink/index.html",
    "href": "posts/source-sink/index.html",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "",
    "text": "resdb = DuckDBClient.of({\n  sourcesink1: FileAttachment(\"sourcesink1.parquet\"),\n  sourcesink1_lookup: FileAttachment(\"sourcesink1_lookup.parquet\"),\n  sourcesink2: FileAttachment(\"sourcesink2.parquet\"),\n  sourcesink2_lookup: FileAttachment(\"sourcesink2_lookup.parquet\"),\n  sourcesink3: FileAttachment(\"sourcesink3.parquet\"),\n  sourcesink3_lookup: FileAttachment(\"sourcesink3_lookup.parquet\")\n})\n\n\n\n\n\n\n\n\nSource-sink modelContagion modelGame-theoretic model\n\n\n\nDescription\nThe key ingredients of the source-sink model1 are groups \\(G\\) of various size with a certain number of adopters \\(i\\) and of institution of level \\(\\ell\\). We assume that with higher levels of institutional strength, \\(\\ell\\), the institution will more effectively promote group-beneficial behavior, \\(\\ell\\)\\(\\beta\\). As it gets better, each adopter in the group also gain a collective benefit \\(b\\). But all of these toodily-doo perks are offset by an institutional implementation costs, \\(c\\), of entertaining larger groups. For instance, think of the process of unionization, promoting behaviors that are costly at individual level. When unionization becomes more successful, the unions can become ungaingly. Lastly adopters lose their behavioural trait at a rate \\(\\gamma\\).\nFirst master equation2:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{diff} &= \\ell \\mathbin{\\color{darkgreen}{\\beta}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\ell\\mathbin{\\color{darkgreen}{\\beta}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\mathbin{\\color{red}{\\gamma}}(i+1)G_{i+1,\\ell} - \\mathbin{\\color{red}{\\gamma}} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\color{blue}{\\rho}} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\nSecond master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{select} &= \\mathbin{\\color{blue}{\\rho}} [G_{i,\\ell-1}(Z_\\ell Z_{\\ell-1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}}) + G_{i,\\ell+1}(Z\\ell Z_{\\ell + 1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}})] \\\\\n                                &-\\mathbin{\\color{blue}{\\rho}}(Z_{\\ell-1}Z_\\ell^{-1} + Z_{\\ell+1}^{-1} + 2\\mathbin{\\color{midnightblue}{\\mu}})G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(Z_\\ell = \\frac{\\sum_{i'} exp(\\mathbin{\\color{seagreen}{b}}i'- \\mathbin{\\color{darkred}{c}}\\ell)G_{i',\\ell}}{\\sum_{i'}G_{i',\\ell}}\\). Note that we add a constant rate of transition \\(\\mu\\) to the selection proces.\nTaken together we have the set of master equations:\n\\[\n\\frac{d}{dt}G_{i,\\ell} = \\frac{d}{dt}G_{i,\\ell}^{diff} + \\frac{d}{dt}G_{i,\\ell}^{select}\n\\]\n\n\nClick to see the Julia code\n\nfunction source_sink!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n      n_adopt = collect(0:(n-1))\n      Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])\n      pop[ℓ]  = sum(G.x[ℓ])\n      R       += sum(ρ*n_adopt .* G.x[ℓ])\n      pop[ℓ] &gt; 0.0 && ( Z[ℓ] /= pop[ℓ] )\n    end\n\n    for ℓ = 1:L, i = 1:n\n      n_adopt, gr_size = i-1, n-1\n\n      # Diffusion events\n      du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - (ℓ-1)*β*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n\n      n_adopt &gt; 0 && ( du.x[ℓ][i] += β*(ℓ-1)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n      n_adopt &lt; gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n\n      # Group selection process\n      ℓ &gt; 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n      ℓ &lt; L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n    end\nend\n\n\n\nPlayground\n\n\nsourcesink1_lookup = resdb.query(\"SELECT param_str::STRING as name, row_id FROM sourcesink1_lookup\")\n\n// TODO: Ideally we would like to have resdb return a lookup\nsourcesink1_lookup_map = sourcesink1_lookup.reduce(function(map, obj) {\n    map[obj.name] = obj.row_id;\n    return map;\n}, {})\n\nlookup1 = {\n  const out = {}\n  out['idx2name'] = {0: \"β\", 1: 'γ', 2: 'ρ', 3: 'b', 4: 'c', 5: 'μ'}\n  out['name2idx'] = {\"β\": 0, 'γ': 1, 'ρ': 2, 'b': 3, 'c': 4, 'μ': 5}\n  return out\n}\n\np1 = get_param_table(sourcesink1_lookup_map, lookup1)\n\nav1 = [\"β\", \"b\", \"c\"] \n// fy1 = \"α\"  // choose the facet variable\nfp1 = [\"γ\", \"ρ\", \"μ\"]\n\nviewof s1 = Inputs.form({\n  ax0: Inputs.range(p1[av1[0]]['minmax'], {step: p1[av1[0]]['s'], label: av1[0]}),\n  ax1: Inputs.range(p1[av1[1]]['minmax'], {step: p1[av1[1]]['s'], label: av1[1]}),\n  ax2: Inputs.range(p1[av1[2]]['minmax'], {step: p1[av1[2]]['s'], label: av1[2]}),\n  fp0: Inputs.range(p1[fp1[0]]['minmax'], {step: p1[fp1[0]]['s'], label: fp1[0], value: p1[fp1[0]]['first_val']}),\n  fp1: Inputs.range(p1[fp1[1]]['minmax'], {step: p1[fp1[1]]['s'], label: fp1[1], value: p1[fp1[1]]['first_val']}),\n  fp2: Inputs.range(p1[fp1[2]]['minmax'], {step: p1[fp1[2]]['s'], label: fp1[2], value: p1[fp1[2]]['first_val']})\n})\n\nviewof r1 = Inputs.form({\n  x: Inputs.radio(av1, {label: \"x\", value: av1[0]}),\n  y: Inputs.radio(av1, {label: \"y\", value: av1[1]})\n})\n\n\ndata = sql_data_a('sourcesink1', sourcesink1_lookup_map[`${f(s1['ax0'])}_${f(s1['fp0'])}_${f(s1['fp1'])}_${f(s1['ax1'])}_${f(s1['ax2'])}_${f(s1['fp2'])}`])\ndatab = sql_data_b('sourcesink1')\ndata_hm = get_data_heatmap(datab, lookup1, fp1, av1, r1, s1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`\n    &lt;div style=\"display:flex; \"&gt;\n      &lt;div&gt;${ plot_time_evo(data, \"value\", \"reds\") }&lt;/div&gt;\n      &lt;div&gt;${ plot_time_evo(data, \"value_prop\", \"blues\")}&lt;/div&gt;\n    &lt;/div&gt;\n`\n\n\n\n\n\n\n\n\n\n\npd1 = phase_diagram(data_hm, r1['x'], r1['y'], 'value_prop', 'blues')\npd1d = phase_diagram(global_hm(data_hm),  r1['x'], r1['y'], 'value', 'viridis') \n\nhtml`\n    &lt;div style=\"display:flex; \"&gt;\n    &lt;div&gt;\n      &lt;div&gt;${ pd1 }&lt;/div&gt;\n      &lt;div&gt;${ pd1.legend('color', {label: \"Level proportion →\", width: 350, marginLeft: 150})\n }&lt;/div&gt;\n    &lt;/div&gt;\n    &lt;div&gt;\n      &lt;div&gt;${ pd1d }&lt;/div&gt;\n      &lt;div&gt;${ pd1d.legend('color', {label: \"Global Frequency of behavior →\", width: 350, marginLeft: 150}) }&lt;/div&gt;\n    &lt;/div&gt;\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTakeaways\n\nFrequency of behaviour in groups with different institutional strength.\nWithin groups, the frequency of cooperative behaviour follows the strength of institutions (with ℓ = 1 in light beige and ℓ = 6 in dark red).\nQualitatively, no institutions are possible if institutional costs are too high, and the behaviour never spreads.\nThe time dynamics of global behavioural frequency and behaviour in groups can include patterns of surge and collapse.\n\n\n\n\n\nDescription\nThe key difference in that model from the last is that contagion is something to be limited by institutions of various levels. As such, \\(\\beta\\) in our model now must be negative while \\(\\alpha\\) must be positive for transmission to fall with \\(\\ell\\).\nWe ask ourselves to what extent the contagion is able to spread with very little \\(\\beta\\) values.\nWe want institutions to be able to stop contagions but contagion must exist in the first place.\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{\\text{epi}} &= \\beta {\\color{red}{\\ell}}^{\\color{red}{-\\alpha}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\beta {\\color{red}{\\ell}}^{\\color{red}{-\\alpha}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\gamma(i+1)G_{i+1,\\ell} - \\mathbin{\\gamma} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\rho} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\n\n\nClick to see the Julia code\n\nfunction source_sink2!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, α, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n        n_adopt = collect(0:(n-1))\n        Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ]) \n        pop[ℓ]  = sum(G.x[ℓ])\n        R      += sum(ρ * n_adopt .* G.x[ℓ]) \n        pop[ℓ] &gt; 0.0 && ( Z[ℓ] /= pop[ℓ] ) \n      end\n      \n      for ℓ = 1:L, i = 1:n\n        n_adopt, gr_size = i-1, n-1\n        # Diffusion events\n        du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - β*(ℓ^-α)*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n        n_adopt &gt; 0 && ( du.x[ℓ][i] += β*(ℓ^-α)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n        n_adopt &lt; gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n        # Group selection process\n        ℓ &gt; 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n        ℓ &lt; L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n      end\nend\n\n\n\nClick to see the parameters definition\n\n\nβ: Spreading rate from non-adopter to adopter beta\nξ: Simple-complex contagion parameter\nα: Negative benefits alpha\nγ: Recovery rate gamma, i.e rate at which adopters loose behavioral trait\nρ: rate between groups to spread the contagion\nη: rate between groups to spread the institution level.\nb: Group benefits b\nc: Institutional cost c\nμ: Noise u\n\n\n\n\nPlayground\n\n\nsourcesink2_lookup = resdb.query(\"SELECT param_str::STRING as name, row_id FROM sourcesink2_lookup\")\n\n// TODO: Ideally we would like to have resdb return a lookup\nsourcesink2_lookup_map = sourcesink2_lookup.reduce(function(map, obj) {\n    map[obj.name] = obj.row_id;\n    return map;\n}, {})\n\nlookup2 = {\n  const out = {}\n  out['idx2name'] = {0: 'β', 1: 'ξ', 2: 'α', 3: 'γ', 4: 'ρ', 5: 'η', 6: 'b', 7: 'c', 8:'μ'}\n  out['name2idx'] = {'β': 0, 'ξ': 1, 'α': 2, 'γ': 3, 'ρ': 4, 'η': 5, 'b': 6, 'c': 7, 'μ': 8}\n  return out\n}\n\np2 = get_param_table(sourcesink2_lookup_map, lookup2)\n\nax_vars2 = [\"β\", \"ρ\", \"η\"] // choose the x,y,z axis, i.e. params to vary\nfy2 = \"α\"  // choose the facet variable\nfp2 = [\"ξ\", \"α\", \"γ\", \"b\", \"c\", \"μ\"]\n\n\nviewof r2 = Inputs.form({\n  x: Inputs.radio(ax_vars2, {label: \"x\", value: ax_vars2[0]}),\n  y: Inputs.radio(ax_vars2, {label: \"y\", value: ax_vars2[1]})\n})\n\nviewof s2 = Inputs.form({\n  ax0: Inputs.range(p2[ax_vars2[0]]['minmax'], {step: p2[ax_vars2[0]]['s'], label: ax_vars2[0]}),\n  ax1: Inputs.range(p2[ax_vars2[1]]['minmax'], {step: p2[ax_vars2[1]]['s'], label: ax_vars2[1]}),\n  ax2: Inputs.range(p2[ax_vars2[2]]['minmax'], {step: p2[ax_vars2[2]]['s'], label: ax_vars2[2]}),\n  fp0: Inputs.range(p2[fp2[0]]['minmax'], {step: p2[fp2[0]]['s'], label: fp2[0], value: p2[fp2[0]]['first_val']}),\n  fp1: Inputs.range(p2[fy2]['minmax'], {step: p2[fy2]['s'], label: fy2, value: p2[fy2]['first_val']}),\n  fp2: Inputs.range(p2[fp2[2]]['minmax'], {step: p2[fp2[2]]['s'], label: fp2[2], value: p2[fp2[2]]['first_val']}),\n  fp3: Inputs.range(p2[fp2[3]]['minmax'], {step: p2[fp2[3]]['s'], label: fp2[3], value: p2[fp2[3]]['first_val']}),\n  fp4: Inputs.range(p2[fp2[4]]['minmax'], {step: p2[fp2[4]]['s'], label: fp2[4], value: p2[fp2[4]]['first_val']}),\n  fp5: Inputs.range(p2[fp2[5]]['minmax'], {step: p2[fp2[5]]['s'], label: fp2[5], value: p2[fp2[5]]['first_val']}),\n})\n\n\ndata2 = sql_data_a('sourcesink2', sourcesink2_lookup_map[`${f(s2['ax0'])}_${f(s2['fp0'])}_${f(s2['fp1'])}_${f(s2['fp2'])}_${f(s2['ax1'])}_${f(s2['ax2'])}_${f(s2['fp3'])}_${f(s2['fp4'])}_${f(s2['fp5'])}`])\ndata2b = sql_data_b(\"sourcesink2\")\ndata_hm2 = get_data_heatmap(data2b, lookup2, fp2, ax_vars2, r2, s2, fy2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`\n    &lt;div style=\"display:flex; \"&gt;\n      &lt;div&gt;${ plot_time_evo(data2, \"value\", \"reds\") }&lt;/div&gt;\n      &lt;div&gt;${ plot_time_evo(data2, \"value_prop\", \"blues\")}&lt;/div&gt;\n    &lt;/div&gt;\n`\n\n\n\n\n\n\n\n\n\n\npd2 = phase_diagram(data_hm2, r2['x'], r2['y'], 'value_prop', \"blues\", fy2)\npd2d = phase_diagram(global_hm(data_hm2),  r2['x'], r2['y'], 'value', 'viridis') \n\nhtml`\n    &lt;div style=\"display:flex; \"&gt;\n    &lt;div&gt;\n      &lt;div&gt;${ pd2 }&lt;/div&gt;\n      &lt;div&gt;${ pd2.legend('color', {label: \"Level proportion →\", width: 350, marginLeft: 150})\n }&lt;/div&gt;\n    &lt;/div&gt;\n    &lt;div&gt;\n      &lt;div&gt;${ pd2d }&lt;/div&gt;\n      &lt;div&gt;${ pd2d.legend('color', {label: \"Global Frequency of behavior →\", width: 350, marginLeft: 150}) }&lt;/div&gt;\n    &lt;/div&gt;\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction\n\nDescription\n\n\n\nPlayground\n\n\n\n\n\n\n\n\n\n\n\n\nModel 1 Sketch\n\n\n\n\n\n\n\n\n\n\n\nfunction sql_data_a(model, name) {\n    return resdb.query(`\n      SELECT timestep::INT as timestep, L::INT as L, value, value_prop\n      FROM ${model}\n      WHERE\n      row_id = '${name}'\n    `)\n}\n\nfunction sql_data_b(model) {\n    return resdb.query(`\n      WITH tmp as (\n          SELECT row_id, L, MAX(timestep::INT) as timestep\n          FROM ${model}\n          GROUP BY row_id, L\n      )\n      SELECT s.value, s.L::INT as L, s.value_prop, ss.param_str::STRING as name\n      FROM ${model} s\n      JOIN tmp\n      ON s.row_id = tmp.row_id AND s.L = tmp.L AND s.timestep = tmp.timestep\n      JOIN ${model}_lookup ss\n      ON s.row_id = ss.row_id\n      ORDER BY (s.row_id, s.L)\n  `)\n}\n\nfunction get_fixed_params(param_table, ax_vars, fx) {\n  const all_params = [...Object.keys(param_table)]\n  const varying_params = typeof fx !== undefined ? new Set(ax_vars) : new Set(ax_vars.concat(fx))\n  const diff_params = new Set(all_params.filter((x) =&gt; !varying_params.has(x)))\n  return Array.from(diff_params)\n}\n\nf = (x) =&gt; Number.isInteger(x) ? x.toPrecision(2) : x\n\n// Extract the step from a list of values for a parameter\ns = (p,i) =&gt; { \n    const unique_vals = Array.from(new Set(p.map(d =&gt; parseFloat(d[i])))).sort((a,b) =&gt; a - b)\n    const out = []\n    for (let i=1; i &lt; unique_vals.length; i++ ) {\n      out.push(+(unique_vals[i]-unique_vals[i-1]).toPrecision(2))\n    } // return whatev if length is zero\n    return out.length === 0 ? 0.1 : out[0]\n}\n\nminmax = (p, i) =&gt; d3.extent(p.map(d =&gt; parseFloat(d[i])))\n\n// Param table where each key is a parameter, and values \n// are list of values relevant to \n// model: resdb output for a specific model\n// lookup: { [0: param1, 1: param2, ...] }\nfunction get_param_table(model_lookup, param_lookup) {\n    \n  const p = Object.keys(model_lookup).map(d =&gt; d.split(\"_\")) \n  \n  const param_table = {}\n  const first_line_param = p[0]\n  for ( let i=0; i &lt; first_line_param.length; i++ ) {\n    param_table[param_lookup['idx2name'][i]] = { \n      's': s(p,i), 'first_val': first_line_param[i], 'minmax': minmax(p,i) \n      }\n  }\n  return param_table\n}\n\n// To get heatmap data, we need\n//   data: data from resdb join `name` and `L`\n//   ax_vars: variables we want as x,y,z\n//   fx: variable to facet\n//   fp: other vars\n//   sliders: set of sliders\nfunction get_data_heatmap(data, lookup, fp, ax_vars, radios, sliders, fx) {\n  const dat_hm = [];\n  \n  for (let i=0; i &lt; data.length; i++) { \n    \n    const p_split = data[i].name.split('_')\n    \n    const vs = {} // dictionary containing all the values of selected parameters \n\n    // Grab the chosen axis0/x, axis1/y, axis2/z\n    const [ax0, ax1, ax2] = ax_vars\n    vs[ax0] = parseFloat(p_split[lookup['name2idx'][ax0]])\n    vs[ax1] = parseFloat(p_split[lookup['name2idx'][ax1]])\n    vs[ax2] = parseFloat(p_split[lookup['name2idx'][ax2]])\n\n    // Grab the Fixed parameters\n    for (let i=0; i &lt; fp.length; i++) {\n      vs[fp[i]] = parseFloat(p_split[lookup['name2idx'][fp[i]]])\n    }\n    \n    // Grab the radios, which will be 2 of the 3 axis vars. \n    // The other other one we'll be the value of our heatmap.\n    // This is where we need to know the actual param_name.\n    const p1 = parseFloat(p_split[lookup['name2idx'][radios['x']]])\n    const p2 = parseFloat(p_split[lookup['name2idx'][radios['y']]])\n    const hm_vals_i = {\n      'L': data[i].L,\n      'fx' : typeof fx !== undefined ? null : p_split[lookup['name2idx'][fx]], \n      'param1': p1,\n      'param2': p2,\n      'param_str': `${p1}/${p2}`, // We need a way to groupby (p1,p2) for `global_hm()`\n      'value': data[i].value,\n      'value_prop': data[i].value_prop\n    }\n\n    if (vs[fp[0]] === sliders['fp0'] && vs[fp[1]] === sliders['fp1'] && vs[fp[2]] === sliders['fp2'] && vs[fp[3]] == sliders['fp3'] && vs[fp[4]] == sliders['fp4']) {\n\n        // if ax1 == x && ax2 ==y, then ax0 == z\n        if (radios['x'] == ax1 && radios['y'] == ax2 && vs[ax0] == sliders['ax0']) {\n             dat_hm.push(hm_vals_i)\n        } else if (radios['x'] == ax0 && radios['y'] == ax2 && vs[ax1] == sliders['ax1']) {\n             dat_hm.push(hm_vals_i)\n        } else if (radios['x'] == ax0 && radios['y'] == ax1 && vs[ax2] == sliders['ax2']) {\n             dat_hm.push(hm_vals_i)\n        }\n    }\n  }\n  return dat_hm\n}\n\nfunction global_hm(d){\n  return d3.flatRollup(d, v =&gt; d3.sum(v, d =&gt; d.value * d.value_prop), d =&gt; d.param_str)\n           .map(currentElement =&gt; ({\n             'param1': parseFloat(currentElement[0].split('/')[0]),\n             'param2': parseFloat(currentElement[0].split('/')[1]),\n             'value': currentElement[1],\n             'L': 1\n          }))\n}\n\n\nfunction plot_time_evo(d, y_vals, pal) {\n  const global_mean = d3.rollup(d, v =&gt; d3.sum(v, d =&gt; d.value * d.value_prop), d =&gt; d.timestep)\n\n  return Plot.plot({\n    x: {type:\"log\"},\n    marginLeft: 50,\n    color: { \n      scheme: pal, \n      type: \"ordinal\", \n      range: [0.3, 1],\n      legend: true \n    },\n    marks: [\n      Plot.lineY(Array.from(global_mean.values()), {\n        strokeDasharray: \"5,3\", opacity: pal == 'blues' ? 0 : 1.\n        }),\n      Plot.line(\n        d, {\n          x: 'timestep', y: y_vals, stroke: \"L\"\n          }),\n      Plot.dot(\n        d, {\n          x: 'timestep', y: y_vals, stroke: \"L\"\n          })\n    ]\n  })\n}\n\nfunction phase_diagram(d, x, y, z, pal, fy) {\n  return PlotDev.plot({\n    width: 1200,\n    height: 600,\n    color: {\n      type: \"linear\",\n      scheme: pal\n    },\n    x: { label: x },\n    y: { label: y },\n    fy: { label: fy },\n    facet: { \n      data: d, \n      x: \"L\", \n      y: typeof fy !== undefined ? 'fx' : null \n    },\n    marks: [\n      PlotDev.raster(d, {\n        x: \"param1\",\n        y: \"param2\",\n        fill: z,\n        interpolate: \"nearest\"\n      }),\n    ]\n  })\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotDev = await import(\"https://esm.sh/@observablehq/plot\");\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\n@article{hebert-dufresne_source-sink_nodate,\ntitle = {Source-sink behavioural dynamics limit institutional evolution in a group-structured society},\nvolume = {9},\nurl = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.211743},\ndoi = {10.1098/rsos.211743},\nnumber = {3},\nurldate = {2022-05-26},\njournal = {Royal Society Open Science},\nauthor = {Hébert-Dufresne, Laurent and Waring, Timothy M. and St-Onge, Guillaume and Niles, Meredith T. and Kati Corlew, Laura and Dube, Matthew P. and Miller, Stephanie J. and Gotelli, Nicholas J. and McGill, Brian J.}},\n}\n↩︎\nA sidenote on master equations for non-physicists. A friendly introductory book on the topic is under construction at https://www.gstonge.ca/tame/chapters/index.html.↩︎"
  }
]