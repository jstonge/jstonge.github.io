[
  {
    "objectID": "posts/source-sink/index.html",
    "href": "posts/source-sink/index.html",
    "title": "Source-sink behavioural dynamics limit institutional evolution in a group structured society",
    "section": "",
    "text": "resdb = DuckDBClient.of({\n  sourcesink1: FileAttachment(\"sourcesink1.parquet\"),\n  sourcesink2: FileAttachment(\"sourcesink2.parquet\"),\n  sourcesink3: FileAttachment(\"sourcesink3.parquet\")\n})\n\n\n\n\n\n\n\n\nSource-sink modelContagion modelGame-theoretic model\n\n\n\nDescription\nThe key ingredients of the source-sink model1 are groups \\(G\\) of various size with a certain number of adopters \\(i\\) and of institution of level \\(\\ell\\). We assume that with higher levels of institutional strength, \\(\\ell\\), the institution will more effectively promote group-beneficial behavior, \\(\\ell\\)\\(\\beta\\). As it gets better, each adopter in the group also gain a collective benefit \\(b\\). But all of these toodily-doo perks are offset by an institutional implementation costs, \\(c\\), of entertaining larger groups. For instance, think of the process of unionization, promoting behaviors that are costly at individual level. When unionization becomes more successful, the unions can become ungaingly. Lastly adopters lose their behavioural trait at a rate \\(\\gamma\\).\nFirst master equation2:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{diff} &= \\ell \\mathbin{\\color{darkgreen}{\\beta}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\ell\\mathbin{\\color{darkgreen}{\\beta}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\mathbin{\\color{red}{\\gamma}}(i+1)G_{i+1,\\ell} - \\mathbin{\\color{red}{\\gamma}} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\color{blue}{\\rho}} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\nSecond master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{select} &= \\mathbin{\\color{blue}{\\rho}} [G_{i,\\ell-1}(Z_\\ell Z_{\\ell-1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}}) + G_{i,\\ell+1}(Z\\ell Z_{\\ell + 1}^{-1} + \\mathbin{\\color{midnightblue}{\\mu}})] \\\\\n                                &-\\mathbin{\\color{blue}{\\rho}}(Z_{\\ell-1}Z_\\ell^{-1} + Z_{\\ell+1}^{-1} + 2\\mathbin{\\color{midnightblue}{\\mu}})G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(Z_\\ell = \\frac{\\sum_{i'} exp(\\mathbin{\\color{seagreen}{b}}i'- \\mathbin{\\color{darkred}{c}}\\ell)G_{i',\\ell}}{\\sum_{i'}G_{i',\\ell}}\\). Note that we add a constant rate of transition \\(\\mu\\) to the selection proces.\nTaken together we have the set of master equations:\n\\[\n\\frac{d}{dt}G_{i,\\ell} = \\frac{d}{dt}G_{i,\\ell}^{diff} + \\frac{d}{dt}G_{i,\\ell}^{select}\n\\]\n\n\nJulia model\nfunction source_sink!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n      n_adopt = collect(0:(n-1))\n      Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])\n      pop[ℓ]  = sum(G.x[ℓ])\n      R       += sum(ρ*n_adopt .* G.x[ℓ])\n      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )\n    end\n\n    for ℓ = 1:L, i = 1:n\n      n_adopt, gr_size = i-1, n-1\n\n      # Diffusion events\n      du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - (ℓ-1)*β*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n\n      n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ-1)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n      n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n\n      # Group selection process\n      ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n      ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n    end\nend\n\n\nPlayground\n\n\nsourcesink1 = resdb.query(`SELECT DISTINCT name FROM sourcesink1`)\nlookup1 = {\n  const out = {}\n  out['idx2name'] = {0: \"β\", 1: 'γ', 2: 'ρ', 3: 'b', 4: 'c', 5: 'μ'}\n  out['name2idx'] = {\"β\": 0, 'γ': 1, 'ρ': 2, 'b': 3, 'c': 4, 'μ': 5}\n  return out\n}\n\np1 = get_param_table(sourcesink1, lookup1)\n\nax_vars1 = [\"β\", \"c\", \"b\"] // choose the x,y,z axis, i.e. params to vary\nfp1 = get_fixed_params(p1, ax_vars1); // fixed params are the rest\n\nviewof s1 = Inputs.form({\n  ax0: Inputs.range(p1[ax_vars1[0]]['minmax'], {step: p1[ax_vars1[0]]['s'], label: ax_vars1[0]}),\n  ax1: Inputs.range(p1[ax_vars1[1]]['minmax'], {step: p1[ax_vars1[1]]['s'], label: ax_vars1[1]}),\n  ax2: Inputs.range(p1[ax_vars1[2]]['minmax'], {step: p1[ax_vars1[2]]['s'], label: ax_vars1[2]}),\n  fp0: Inputs.range(p1[fp1[0]]['minmax'], {step: p1[fp1[0]]['s'], label: fp1[0], value: p1[fp1[0]]['first_val']}),\n  fp1: Inputs.range(p1[fp1[1]]['minmax'], {step: p1[fp1[1]]['s'], label: fp1[1], value: p1[fp1[1]]['first_val']}),\n  fp2: Inputs.range(p1[fp1[2]]['minmax'], {step: p1[fp1[2]]['s'], label: fp1[2], value: p1[fp1[2]]['first_val']})\n})\n\nviewof r1 = Inputs.form({\n  x: Inputs.radio(ax_vars1, {label: \"x\", value: ax_vars1[0]}),\n  y: Inputs.radio(ax_vars1, {label: \"y\", value: ax_vars1[1]})\n})\n\n\ndata = sql_data_a('sourcesink1', `${f(s1['ax0'])}_${f(s1['fp0'])}_${f(s1['fp1'])}_${f(s1['ax2'])}_${f(s1['ax1'])}_${f(s1['fp2'])}`)\ndatab = sql_data_b('sourcesink1')\ndata_hm = get_data_heatmap(datab, lookup1, fp1, ax_vars1, r1, s1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`\n    <div style=\"display:flex; \">\n      <div>${ plot_time_evo(data, \"value\", \"reds\") }</div>\n      <div>${ plot_time_evo(data, \"value_prop\", \"blues\")}</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\npd1 = phase_diagram(data_hm, r1['x'], r1['y'], 'value_prop', 'blues')\n\nhtml`\n    <div style=\"display: flex;\">\n      <div flex-grow=2>${ pd1 }</div>\n      <div flex-grow=0>${ phase_diagram(global_hm(data_hm),  r3['x'], r3['y'], 'value', 'rainbow') }</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npd1.legend('color', {label: \"Global Frequency of behavior →\", width: 350, marginLeft: 150})\n\n\n\n\n\n\n\n\n\n\nTakeaways\n\nFrequency of behaviour in groups with different institutional strength.\nWithin groups, the frequency of cooperative behaviour follows the strength of institutions (with ℓ = 1 in light beige and ℓ = 6 in dark red).\nQualitatively, no institutions are possible if institutional costs are too high, and the behaviour never spreads.\nThe time dynamics of global behavioural frequency and behaviour in groups can include patterns of surge and collapse.\n\n\n\n\n\nDescription\nThe key difference in that model from the last is that contagion is something to be limited by institutions of various levels. As such, \\(\\beta\\) in our model now must be negative while \\(\\alpha\\) must be positive for transmission to fall with \\(\\ell\\).\nWe ask ourselves to what extent the contagion is able to spread with very little \\(\\beta\\) values.\nWe want institutions to be able to stop contagions but contagion must exist in the first place.\n\\[\\begin{align*}\n\\frac{d}{dt}G_{i,\\ell}^{\\text{epi}} &= \\beta {\\color{red}{\\ell}}^{\\color{red}{-\\alpha}} [(i-1) + R](n - i + 1)G_{i-1,\\ell} \\\\\n                              &- \\beta {\\color{red}{\\ell}}^{\\color{red}{-\\alpha}} (i+R)(n-i) G_{i,\\ell} \\\\\n                              &+ \\gamma(i+1)G_{i+1,\\ell} - \\mathbin{\\gamma} i G_{i,\\ell}\n\\end{align*}\\]\nwhere \\(R = \\mathbin{\\rho} \\sum_{i',\\ell'} i'G_{i',\\ell'}\\) represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion \\(\\rho\\).\nfunction source_sink2!(du, u, p, t)\n    G, L, n = u, length(u.x), length(first(u.x))\n    β, α, γ, ρ, b, c, μ = p\n    Z, pop, R = zeros(L), zeros(L), 0.\n\n    # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n        n_adopt = collect(0:(n-1))\n        Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ]) \n        pop[ℓ]  = sum(G.x[ℓ])\n        R      += sum(ρ * n_adopt .* G.x[ℓ]) \n        pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] ) \n      end\n      \n      for ℓ = 1:L, i = 1:n\n        n_adopt, gr_size = i-1, n-1\n        # Diffusion events\n        du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - β*(ℓ^-α)*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]\n        n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ^-α)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])\n        n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )\n        # Group selection process\n        ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )\n        ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )\n      end\nend\n\n\nPlayground\n\n\nsourcesink2 = resdb.query(`SELECT DISTINCT name FROM sourcesink2`)\nlookup2 = {\n  const out = {}\n  out['idx2name'] = {0: 'β', 1: 'ξ', 2: 'α', 3: 'γ', 4: 'ρ', 5: 'η', 6: 'b', 7: 'c', 8:'μ'}\n  out['name2idx'] = {'β': 0, 'ξ': 1, 'α': 2, 'γ': 3, 'ρ': 4, 'η': 5, 'b': 6, 'c': 7, 'μ': 8}\n  return out\n}\n\np2 = get_param_table(sourcesink2, lookup2)\n\nax_vars2 = [\"β\", \"ρ\", \"η\"] // choose the x,y,z axis, i.e. params to vary\nfy2 = \"α\"  // choose the facet variable\nfp2 = [\"ξ\", \"α\", \"γ\", \"b\", \"c\", \"μ\"]\n\n\nviewof r2 = Inputs.form({\n  x: Inputs.radio(ax_vars2, {label: \"x\", value: ax_vars2[0]}),\n  y: Inputs.radio(ax_vars2, {label: \"y\", value: ax_vars2[1]})\n})\n\nviewof s2 = Inputs.form({\n  ax0: Inputs.range(p2[ax_vars2[0]]['minmax'], {step: p2[ax_vars2[0]]['s'], label: ax_vars2[0]}),\n  ax1: Inputs.range(p2[ax_vars2[1]]['minmax'], {step: p2[ax_vars2[1]]['s'], label: ax_vars2[1]}),\n  ax2: Inputs.range(p2[ax_vars2[2]]['minmax'], {step: p2[ax_vars2[2]]['s'], label: ax_vars2[2]}),\n  fp0: Inputs.range(p2[fp2[0]]['minmax'], {step: p2[fp2[0]]['s'], label: fp2[0], value: p2[fp2[0]]['first_val']}),\n  fp1: Inputs.range(p2[fy2]['minmax'], {step: p2[fy2]['s'], label: fy2, value: p2[fy2]['first_val']}),\n  fp2: Inputs.range(p2[fp2[2]]['minmax'], {step: p2[fp2[2]]['s'], label: fp2[2], value: p2[fp2[2]]['first_val']}),\n  fp3: Inputs.range(p2[fp2[3]]['minmax'], {step: p2[fp2[3]]['s'], label: fp2[3], value: p2[fp2[3]]['first_val']}),\n  fp4: Inputs.range(p2[fp2[4]]['minmax'], {step: p2[fp2[4]]['s'], label: fp2[4], value: p2[fp2[4]]['first_val']}),\n  fp5: Inputs.range(p2[fp2[5]]['minmax'], {step: p2[fp2[5]]['s'], label: fp2[5], value: p2[fp2[5]]['first_val']}),\n})\n\n\ndata2 = sql_data_a('sourcesink2', `${f(s2['ax0'])}_${f(s2['fp0'])}_${f(s2['fp1'])}_${f(s2['fp2'])}_${f(s2['ax1'])}_${f(s2['ax2'])}_${f(s2['fp3'])}_${f(s2['fp4'])}_${f(s2['fp5'])}`)\n\ndata2b = sql_data_b(\"sourcesink2\")\n\ndata_hm2 = get_data_heatmap(data2b, lookup2, fp2, ax_vars2, r2, s2, fy2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`\n    <div style=\"display:flex; \">\n      <div>${ plot_time_evo(data2, \"value\", \"reds\") }</div>\n      <div>${ plot_time_evo(data2, \"value_prop\", \"blues\")}</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\npd2 = phase_diagram(data_hm2, r2['x'], r2['y'], 'value_prop', fy2)\n\nhtml`\n    <div style=\"display:flex; \">\n      <div>${ pd2 }</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npd2.legend('color', {label: \"Global Frequency of behavior →\", width: 350, marginLeft: 150})\n\n\n\n\n\n\n\n\n\n\n\n\nDescription\nUPDATE DESCRIPTION. WHY DO WE CARE. IS IT USEFUL FOR POLICY?! WHO AM I?\nfunction source_sink3!(du, u, p, t)\n  G, L, n = u, lengts(u.x), lengts(u.x[1])\n  β, γ, ρ, b, c, μ, δ = p # δ = 1 (δ = 0): (no) resource requirement to upgrade institution\n  Z, pop, R = zeros(L), zeros(L), 0.\n\n  # Calculate mean-field coupling and observed fitness landscape\n    for ℓ in 1:L\n      n_adopt = collect(0:(n-1))\n      Z[ℓ]    = sum(f.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])\n      pop[ℓ]  = sum(G.x[ℓ])\n      R      += sum(n_adopt .* G.x[ℓ]) # Global diffusion\n      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )\n    end\n\n    for ℓ = 1:L, i = 1:n\n      n_adopt, gr_size = i-1, n-1\n      # Individual selection process\n      du.x[ℓ][i] = -n_adopt*f(1-s(ℓ))*G.x[ℓ][i] - (gr_size-n_adopt)*f(s(ℓ)-1)*G.x[ℓ][i]\n      du.x[ℓ][i] += - n_adopt*(gr_size-n_adopt)*(β+γ)*G.x[ℓ][i] - ρ*(gr_size-n_adopt)*β*R*G.x[ℓ][i] - ρ*n_adopt*γ*(gr_size-R)*G.x[ℓ][i]\n      n_adopt > 0 && ( du.x[ℓ][i] += (gr_size-n_adopt+1)*f(s(ℓ)-1)*G.x[ℓ][i-1] + β*(n_adopt-1+ρ*R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1] )\n      n_adopt < gr_size && ( du.x[ℓ][i] += (n_adopt+1)*f(1-s(ℓ))*G.x[ℓ][i+1] + γ*(gr_size-n_adopt-1+ρ*(gr_size-R))*(n_adopt+1)*G.x[ℓ][i+1] )\n      # Group selection process\n      ℓ > 1 && ( du.x[ℓ][i] += (f(b*n_adopt-c*(ℓ-1))^δ)*(μ+ρ*Z[ℓ]/Z[ℓ-1])*G.x[ℓ-1][i] - (μ*(f(c*(ℓ-1)-b*n_adopt)^δ)+ρ*(f(b*n_adopt-c*(ℓ-2))^δ)*Z[ℓ-1]/Z[ℓ])*G.x[ℓ][i] )\n      ℓ < L && ( du.x[ℓ][i] += (μ*(f(c*ℓ-b*n_adopt)^δ)+ρ*(f(b*n_adopt-c*(ℓ-1))^δ)*Z[ℓ]/Z[ℓ+1])*G.x[ℓ+1][i] - (f(b*n_adopt-c*ℓ)^δ)*(μ+ρ*Z[ℓ+1]/Z[ℓ])*G.x[ℓ][i] )\n    end\nend\n\n\nPlayground\n\n\nsourcesink3 = resdb.query(`SELECT DISTINCT name FROM sourcesink3`)\n\nlookup3 = {\n  const out = {}\n  out['idx2name'] = {0: \"β\", 1: 'γ', 2: 'ρ', 3: 'b', 4: 'c', 5: 'μ', 6: 'δ', 7: 'α'}\n  out['name2idx'] = {\"β\": 0, 'γ':1, 'ρ': 2, 'b': 3, 'c': 4, 'μ': 5, 'δ': 6, 'α': 7}\n  return out\n}\n\np3 = get_param_table(sourcesink3, lookup3)\n\nav3 = [\"β\", \"ρ\", 'α']           // ax vars\nfy3 = \"δ\"                       // facet y var\nfp3 = [\"γ\", \"b\", \"c\", \"μ\", fy3] // fixed param vars\n\n// sliders\nviewof s3 = Inputs.form({\n  ax0: Inputs.range(p3[av3[0]]['minmax'], {step: p3[av3[0]]['s'], label: av3[0]}),\n  ax1: Inputs.range(p3[av3[1]]['minmax'], {step: p3[av3[1]]['s'], label: av3[1]}),\n  ax2: Inputs.range(p3[av3[2]]['minmax'], {step: p3[av3[2]]['s'], label: av3[2]}),\n  fp0: Inputs.range(p3[fp3[0]]['minmax'], {step: p3[fp3[0]]['s'], label: fp3[0], value: p3[fp3[0]]['first_val']}),\n  fp1: Inputs.range(p3[fp3[1]]['minmax'], {step: p3[fp3[1]]['s'], label: fp3[1], value: p3[fp3[1]]['first_val']}),\n  fp2: Inputs.range(p3[fp3[2]]['minmax'], {step: p3[fp3[2]]['s'], label: fp3[2], value: p3[fp3[2]]['first_val'], disabled: true}),\n  fp3: Inputs.range(p3[fp3[3]]['minmax'], {step: p3[fp3[3]]['s'], label: fp3[3], value: p3[fp3[3]]['first_val'], disabled: true}),\n  fp4: Inputs.range(p3[fp3[4]]['minmax'], {step: p3[fp3[4]]['s'], label: fp3[4], value: p3[fp3[4]]['first_val'], disabled: true})\n})\n\n// radios\nviewof r3 = Inputs.form({\n  x: Inputs.radio(av3, {label: \"x\", value: av3[0]}),\n  y: Inputs.radio(av3, {label: \"y\", value: av3[1]})\n})\n\n// data\ndata3a = sql_data_a('sourcesink3', `${f(s3[\"ax0\"])}_${f(s3[\"fp0\"])}_${f(s3[\"ax1\"])}_${f(s3[\"fp1\"])}_${f(s3[\"fp2\"])}_${f(s3[\"fp3\"])}_${f(s3[\"fp4\"])}_${f(s3[\"ax2\"])}`)\ndata3b = sql_data_b(\"sourcesink3\")\ndata_hm3 = get_data_heatmap(data3b, lookup3, fp3, av3, r3, s3, fy3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`\n    <div style=\"display:flex; \">\n      <div>${ plot_time_evo(data3a, \"value\", \"reds\") }</div>\n      <div>${ plot_time_evo(data3a, \"value_prop\", \"blues\")}</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\npd3 = phase_diagram(data_hm3,  r3['x'], r3['y'], 'value_prop', 'blues', fy3)\n\nhtml`\n    <div style=\"display:flex; \">\n      <div>${ pd3 }</div>\n      <div>${ phase_diagram(global_hm(data_hm3),  r3['x'], r3['y'], 'value', 'rainbow') }</div>\n    </div>\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npd3.legend('color', {label: \"Global Frequency of behavior →\", width: 350, marginLeft: 150})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 1 Sketch\n\n\n\n\n\n\n\n\n\n\n\nfunction sql_data_a(model, name) {\n    return resdb.query(`\n      SELECT timestep::INT as timestep, L::INT as L, value, value_prop, name\n      FROM ${model}\n      WHERE\n      name = '${name}'\n    `)\n}\n\nfunction sql_data_b(model) {\n    return resdb.query(`\n      WITH tmp as (\n          SELECT name, L, MAX(timestep::INT) as timestep\n          FROM ${model}\n          GROUP BY name, L\n      )\n      SELECT s.name, s.value, s.L::INT as L, s.value_prop\n      FROM ${model} s\n      JOIN tmp\n      ON s.name = tmp.name AND s.L = tmp.L AND s.timestep = tmp.timestep \n  `)\n}\n\n\nfunction global_hm(d){\n  return d3.flatRollup(d, v => d3.sum(v, d => d.value * d.value_prop), d => d.param_str)\n           .map(currentElement => ({\n             'param1': parseFloat(currentElement[0].split('/')[0]),\n             'param2': parseFloat(currentElement[0].split('/')[1]),\n             'value': currentElement[1],\n             'L': 1\n          }))\n}\n\nfunction get_fixed_params(param_table, ax_vars, fx) {\n  const all_params = [...Object.keys(param_table)]\n  const varying_params = typeof fx !== undefined ? new Set(ax_vars) : new Set(ax_vars.concat(fx))\n  const diff_params = new Set(all_params.filter((x) => !varying_params.has(x)))\n  return Array.from(diff_params)\n}\n\nf = (x) => Number.isInteger(x) ? x.toPrecision(2) : x\n\n// Param table where each key is a parameter, and values \n// are list of values relevant to \n// model: resdb output for a specific model\n// lookup: { [0: param1, 1: param2, ...] }\nfunction get_param_table(model, lookup) {\n  \n  // Extract the step from a list of values for a parameter\n  const s = (p,i) => { \n    const unique_vals = Array.from(new Set(p.map(d => parseFloat(d[i])))).sort((a,b) => a - b)\n    const out = []\n    for (let i=1; i < unique_vals.length; i++ ) {\n      out.push(+(unique_vals[i]-unique_vals[i-1]).toPrecision(2))\n    } // return whatev if length is zero\n    return out.length === 0 ? 0.1 : out[0]\n  }\n\n  const minmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\n  \n  const p = model.map(d => d.name.split(\"_\"))\n  \n  const param_table = {}\n  const first_line_param = p[0]\n  for ( let i=0; i < first_line_param.length; i++ ) {\n    param_table[lookup['idx2name'][i]] = { \n      's': s(p,i), 'first_val': first_line_param[i], 'minmax': minmax(p,i) \n      }\n  }\n  return param_table\n}\n\n// To get heatmap data, we need\n//   data: data from resdb join `name` and `L`\n//   ax_vars: variables we want as x,y,z\n//   fx: variable to facet\n//   fp: other vars\n//   sliders: set of sliders\nfunction get_data_heatmap(data, lookup, fp, ax_vars, radios, sliders, fx) {\n  const dat_hm = [];\n  \n  for (let i=0; i < data.length; i++) { \n    \n    const p_split = data[i].name.split('_')\n    \n    const vs = {} // dictionary containing all the values of selected parameters \n\n    const [ax0, ax1, ax2] = ax_vars\n    vs[ax0] = parseFloat(p_split[lookup['name2idx'][ax0]])\n    vs[ax1] = parseFloat(p_split[lookup['name2idx'][ax1]])\n    vs[ax2] = parseFloat(p_split[lookup['name2idx'][ax2]])\n\n    for (let i=0; i < fp.length; i++) {\n      vs[fp[i]] = parseFloat(p_split[lookup['name2idx'][fp[i]]])\n    }\n    \n    const p1 = parseFloat(p_split[lookup['name2idx'][radios['x']]])\n    const p2 = parseFloat(p_split[lookup['name2idx'][radios['y']]])\n    const hm_vals_i = {\n      'L': data[i].L,\n      'fx' : typeof fx !== undefined ? null : p_split[lookup['name2idx'][fx]], \n      'param1': p1,\n      'param2': p2,\n      'param_str': `${p1}/${p2}`,\n      'value': data[i].value,\n      'value_prop': data[i].value_prop\n    }\n\n    if (vs[fp[0]] === sliders['fp0'] && vs[fp[1]] === sliders['fp1'] && vs[fp[2]] === sliders['fp2'] && vs[fp[3]] == sliders['fp3'] && vs[fp[4]] == sliders['fp4']) {\n\n        // if ax1 == x && ax2 ==y, then ax0 == z\n        if (radios['x'] == ax1 && radios['y'] == ax2 && vs[ax0] == sliders['ax0']) {\n             dat_hm.push(hm_vals_i)\n        } else if (radios['x'] == ax0 && radios['y'] == ax2 && vs[ax1] == sliders['ax1']) {\n             dat_hm.push(hm_vals_i)\n        } else if (radios['x'] == ax0 && radios['y'] == ax1 && vs[ax2] == sliders['ax2']) {\n             dat_hm.push(hm_vals_i)\n        }\n    }\n  }\n  return dat_hm\n}\n\nfunction plot_time_evo(d, y_vals, pal) {\n  const global_mean = d3.rollup(d, v => d3.sum(v, d => d.value * d.value_prop), d => d.timestep)\n\n  return Plot.plot({\n    x: {type:\"log\"},\n    marginLeft: 50,\n    color: { \n      scheme: pal, \n      type: \"ordinal\", \n      range: [0.3, 1],\n      legend: true \n    },\n    marks: [\n      Plot.lineY(Array.from(global_mean.values()), {\n        strokeDasharray: \"5,3\", opacity: pal == 'blues' ? 0 : 1.\n        }),\n      Plot.line(\n        d, {\n          x: 'timestep', y: y_vals, stroke: \"L\"\n          }),\n      Plot.dot(\n        d, {\n          x: 'timestep', y: y_vals, stroke: \"L\"\n          })\n    ]\n  })\n}\n\nfunction phase_diagram(d, x, y, z, pal, fy) {\n  return PlotDev.plot({\n    width: 1200,\n    color: {\n      type: \"linear\",\n      scheme: pal\n    },\n    x: { label: x },\n    y: { label: y },\n    fy: { label: fy },\n    facet: { \n      data: d, \n      x: \"L\", \n      y: typeof fy !== undefined ? 'fx' : null \n    },\n    marks: [\n      PlotDev.raster(d, {\n        x: \"param1\",\n        y: \"param2\",\n        fill: z,\n        interpolate: \"nearest\"\n      }),\n    ]\n  })\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotDev = await import(\"https://esm.sh/@observablehq/plot\");\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\n@article{hebert-dufresne_source-sink_nodate, title = {Source-sink behavioural dynamics limit institutional evolution in a group-structured society}, volume = {9}, url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.211743}, doi = {10.1098/rsos.211743}, number = {3}, urldate = {2022-05-26}, journal = {Royal Society Open Science}, author = {Hébert-Dufresne, Laurent and Waring, Timothy M. and St-Onge, Guillaume and Niles, Meredith T. and Kati Corlew, Laura and Dube, Matthew P. and Miller, Stephanie J. and Gotelli, Nicholas J. and McGill, Brian J.}}, }↩︎\nA sidenote on master equations for non-physicists. The citation for master equations in the original paper is the following:\n\nHébert-Dufresne, L., Noël, P.-A., Marceau, V., Allard, A., & Dubé, L. J. (2010). Propagation dynamics on networks featuring complex topologies. Physical Review E, 82(3), 036115. https://doi.org/10.1103/PhysRevE.82.036115\n\nThe term ‘’master equation’’ is not mentionned once in the paper. But they do talk about “a mean-field description used to coherently couple the dynamics of the network elements (nodes, vertices, individuals…) and their recurrent topological patterns (subgraphs, groups…)” that yields a set of ODEs for the time evolution of the system. Another paper writen by Guillaume St-Onge et al. is a more generous in their description of master equation:\n\nSt-Onge, G., Thibeault, V., Allard, A., Dubé, L. J., & Hébert-Dufresne, L. (2021). Master equation analysis of mesoscopic localization in contagion dynamics on higher-order networks. Physical Review E, 103(3), 032301. https://doi.org/10.1103/PhysRevE.103.032301\n\nIn it, section II does a great job of describing what master equations are and why they are powerful modeling tools. Relevant to this model, we learn that the size of a group is determined by drawing from a group size distribution. This is what we do in our intialization scheme above. We also learn that these 3 following papers are relevant to understand master equations:\n\nLindquist, J., Ma, J., van den Driessche, P., & Willeboordse, F. H. (2011). Effective degree network disease models. Journal of Mathematical Biology, 62(2), 143–164. https://doi.org/10.1007/s00285-010-0331-2  Gleeson, J. P. (2011). High-Accuracy Approximation of Binary-State Dynamics on Networks. Physical Review Letters, 107(6), 068701. https://doi.org/10.1103/PhysRevLett.107.068701  Marceau, V., Noël, P.-A., Hébert-Dufresne, L., Allard, A., & Dubé, L. J. (2010). Adaptive networks: Coevolution of disease and topology. Physical Review E, 82(3), 036116. https://doi.org/10.1103/PhysRevE.82.036116\n\n↩︎"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html",
    "href": "posts/sci-group-life-cycle/index.html",
    "title": "Scientific group life cycle",
    "section": "",
    "text": "Model Sketch\n\n\n\n\n\n\n\n\n\nThere are research groups \\(G\\) with a number of non-programmers \\(n\\) and programmers \\(p\\). In a data-driven world, we assume that learning to code confer a large benefit to programmers over non-programmer such that \\(\\alpha << \\beta\\). There is a constant rate of influx of students who do not know how to learn to code in research groups \\(\\mu\\). There is a cost of learning to code \\(c(p,n)\\), which depend on the number of programmers and non-programmers within group. We assume that programmers and non-programmers have different graduation rates, \\(\\nu_p\\) and \\(\\nu_n\\), with \\(\\nu_p > \\nu_n\\).\nWe model the group life cycle with the following master equation:\n\\[\\begin{align*}\n\\frac{d}{dt}G_{n,p} &= \\mu(G_{n-1,p} - G_{n,p}) + \\nu_n \\Big((n+1)G_{n+1,p}-nG_{n,p}\\Big) \\\\\n                           &+ \\Big[ \\tau_g(n+1,p-1)(1-c(n+1, p-1)G_{n+1,p-1} - \\tau_g(n,p)G_{n,p} \\Big] \\\\\n                   &+ \\nu_p\\Big((p+1)G_{n,p+1} - pG_{n,p} \\Big) \\\\\n                   &+ \\tau_g(n+1,p)(1-c(n+1,p))G_{n+1,p}\n\\end{align*}\\]\nLearning to code confers a collective benefits on individuals \\(\\tau_g(n,p; \\alpha, \\beta) \\propto \\frac{\\bar{Z}_{n,p}}{Z_{n,p}}\\), where\n\\[\\log(Z_{n,p}) \\sim \\alpha * n + \\beta * p\\] \\[\\log(\\bar{Z}_{n,p}) \\sim \\alpha (n-1) +\\beta (c * p + (1-c)(p+1))\\]\nWe can think of \\(\\bar{Z}_{n,p}\\) as the potential benefits over \\(Z_{n,p}\\). Reorganizing the terms, we get:\n\\[\\begin{align*}\n\\log[\\tau_g(n,p; \\alpha, \\beta))] &= \\alpha (n-1) +\\beta (c * p + (1-c)(p+1)) - \\alpha * n + \\beta * p \\\\\n                                  &= -\\alpha + \\beta(1-c)\n\\end{align*}\\]\nNote that \\(\\tau_g\\) ends up being a function of \\(n, p\\) through the cost function: \\[c(n,p) = c_0*e^{-\\frac{p}{n}}\\]\nYou can explore both functions below:\n\n\n\n\n\n\nCost function\n\n\n\n\n\n\nfunction cost_prog(n, i, c_0) { return c_0 * Math.exp(-i/n); }\nfunction cost_prog2(n, i, c_0) { return c_0 * Math.exp(-i/(n+i)); }\n\nmax_gr_size = 20\nviewof N = Inputs.range([1, max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof coder = Inputs.range([0, (N-1)], {value: 10, step: 1, label: \"# coder\"})\nviewof c_0 = Inputs.range([0, 1], {value: 0.95, step: 0.01, label: \"c₀\"})\nviewof nc = Inputs.range([1, N], {value: (N-coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc(n,p) = c₀ * exp(-p/n)c(n,p) = c₀ * exp(-p/(n+p))\n\n\n\nnon_coder = N - coder\nxs = [...Array(N).keys()];\nys = xs.map(x => cost_prog(non_coder, x, c_0))\n\n\nPlot.lineY(ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\nx2s = [...Array(N).keys()];\ny2s = x2s.map(x => cost_prog2(non_coder, x, c_0))\n\nPlot.lineY(y2s).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ c(n,p)\", domain:[0,1] },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  =   \\(c(n,p)\\) =  (c=1 means that non-coders always fail to learn to code; c=0 means non-coders always succeed) Non-programmers can still learn to code when \\(p=0\\) because of \\(c_0\\) I woudl expect a bigger difference when we go from no prorammers in the team to one programmer\n\n\n\n\n\n\n\n\n\n\n\n\nGroup benefits\n\n\n\n\n\n\nfunction tau(n, i, alpha, beta) {\n    const c = cost_prog(n, i, 1)\n    return Math.exp(-alpha + beta*(1 - c))\n}\n\ntau_max_gr_size = 20\nviewof tau_alpha = Inputs.range([2, 4], {value: 1., step: 1, label: \"α\", format: x => 10**-x})\nviewof tau_beta = Inputs.range([1, 3], {value: 1., step: 1, label: \"β\", format: x => 10**-x})\nviewof tau_N = Inputs.range([0, tau_max_gr_size], {value: 20, step: 1, label: \"group Size\"})\nviewof tau_coder = Inputs.range([1, tau_max_gr_size], {value: 10, step: 1, label: \"# coder\"})\nviewof tau_nc = Inputs.range([1, max_gr_size], {value: (tau_N-tau_coder), step: 1., label: \"# non-coder\", disabled:true})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nτ(n,p) 1\n\n\n\ntau_non_coder = tau_N - tau_coder\ntau_xs = [...Array(tau_N).keys()];\ntau_ys = tau_xs.map(x => tau(tau_non_coder, x, 10**-tau_alpha, 10**-tau_beta))\n\nPlot.lineY(tau_ys).plot({\n    height: 400, width: 450, grid: true,\n    y: { label: \"↑ τ(α,β;n,p)\" },\n    x: { label: \"p/n →\" }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p/n\\) \\(\\Rightarrow\\) /  ="
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#julia-model",
    "href": "posts/sci-group-life-cycle/index.html#julia-model",
    "title": "Scientific group life cycle",
    "section": "Julia model",
    "text": "Julia model\n\n\n\n\n\n\nInitialization scheme\n\n\n\n\n\nfunction initialize_u0(;N::Int=20)\n  N += 1 # add column for zeroth case\n  G = zeros(N, N)\n  \n  for i=1:N, j=1:N\n    G[i,j] = 1/(N*N)\n  end\n  return ArrayPartition(Tuple([G[n,:] for n=1:N]))\nend\n\nμ  = 0.001   # inflow new students-non coders\nνₙ = 0.01    # death rate non-coders\nνₚ = 0.05    # death rate coders\nα  = 0.01    # benefits non coders\nβ  = 0.1     # benefits coders\np  = [μ, νₙ, νₚ, α, β]\n\nn = 9\nu₀ = initialize_u0(N=n)\ntspan = (0., 1000.)\n\n\n\nc(n, i) = 0.95 * exp(-i / n) # cost function\nτ(n, i, α, β) = exp(-α + β*(1 - c(n, i))) # group benefits\n\nfunction life_cycle_research_groups!(du, u, p, t)\n\n  G, N, P = u, length(u.x), length(first(u₀.x)) # Note that there can be no coders but not non-coders\n  μ, νₙ, νₚ, α, β = p\n  for n=1:N, i=1:P\n    println(\"n:$(n), i:$(i), G.x[n][i]:$(G.x[n][i])\")\n    coder, non_coder = i-1, n-1   # we distinguish indices from actual values.\n    \n    du.x[n][i] = 0\n\n    non_coder > 0 && ( du.x[n][i] += μ*(G.x[n-1][i]) )                # 1st term\n    \n    # for everybody\n    # println(\"2: $(νₙ*non_coder*G.x[n][i])\")\n    du.x[n][i] -= νₙ*non_coder*G.x[n][i]\n    # println(\"3: $(νₚ*coder*G.x[n][i])\")\n    du.x[n][i] -= νₚ*coder*G.x[n][i]\n\n    # upper boxes don't exist \n    if i < P\n      # non_coder > 0 && println(\"4: $(τ(non_coder, coder, α, β)*G.x[n][i] )\")\n      # We don't want to pass non_coder = 0 to τ()\n      non_coder > 0 && ( du.x[n][i] -= τ(non_coder, coder, α, β)*G.x[n][i] )               # 4th term\n      # println(\"5: $(νₚ*(coder+1)*G.x[n][i+1])\")\n      du.x[n][i] += νₚ*(coder+1)*G.x[n][i+1]  # 5th term\n    end\n    \n    # the bottom boxes don't exist\n    if n < N\n      # println(\"6: $(μ*G.x[n][i])\")\n      du.x[n][i] -= μ*G.x[n][i]                                       # 1st term\n      du.x[n][i] += τ(non_coder+1, coder, α, β)*(c(non_coder+1, coder))*G.x[n+1][i]     # 6th term\n      du.x[n][i] += νₙ*(non_coder+1)*G.x[n+1][i]                                            # 2nd term\n      coder > 0 && ( du.x[n][i] += τ(non_coder+1, coder-1, α, β)*(1-c(non_coder+1, coder-1))*G.x[n+1][i-1] ) # 3rd term \n    end\n  end\nend"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#output",
    "href": "posts/sci-group-life-cycle/index.html#output",
    "title": "Scientific group life cycle",
    "section": "Output",
    "text": "Output\n\ndata = FileAttachment(\"data.json\").json()\np = Object.keys(data).map(d => d.split(\"_\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nminmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))\n\nviewof N_    = Inputs.range(minmax(p,0), {step: 1, label: \"N\", value:\"4\"})\nviewof mu    = Inputs.range(minmax(p,1), {step: 0.03, label: \"μ\", value:\"0.0001\"})\nviewof nu_n  = Inputs.range(minmax(p,2), {step: 0.05, label: \"νₙ\", value:\"0.01\"})\nviewof nu_p  = Inputs.range(minmax(p,3), {step: 0.1,  label: \"νₚ\", value:\"0.05\"})\nviewof alpha = Inputs.range(minmax(p,4), {step: 0.15, label: \"α\", value:\"0.01\"})\nviewof beta  = Inputs.range(minmax(p,5), {step: 0.05, label: \"β\", value:\"0.1\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\n\n\n\nf = (x) => x.toPrecision() ? x.toPrecision(2) : x\n\nPlot.plot({\n  x: {type:\"log\"},\n  y: {domain: [0,1]},\n  color: {scheme: \"reds\", type: \"ordinal\", legend: true},\n  marks: [\n    Plot.line(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        }),\n    Plot.dot(\n      data[`${N_}_${mu}_${nu_n}_${nu_p}_${alpha}_${beta}`], {\n        x: 'timesteps', y: \"value\", stroke: \"N\"\n        })\n  ]\n})"
  },
  {
    "objectID": "posts/sci-group-life-cycle/index.html#takeaways",
    "href": "posts/sci-group-life-cycle/index.html#takeaways",
    "title": "Scientific group life cycle",
    "section": "Takeaways:",
    "text": "Takeaways:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]