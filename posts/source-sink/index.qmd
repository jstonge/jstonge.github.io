---
title: "Source-sink behavioural dynamics limit institutional evolution in a group structured society"
description: This model describes behaviors that require institutional strength to get off the ground. But as you add institutional levels to your collective, there is a cost. The model finds organizational free-riding, with some organizations preferring others to pay the cost of institutional strength while benefiting the behaviors emerging from those.
format:
  html:
    echo: false
editor: visual
categories:
  - Approximate Master Equations
  - Institutions
image: unions.jpg
---

```{ojs load results db}
resdb = DuckDBClient.of({
  sourcesink1: FileAttachment("sourcesink1.parquet"),
  sourcesink1_lookup: FileAttachment("sourcesink1_lookup.parquet"),
  sourcesink2: FileAttachment("sourcesink2.parquet"),
  sourcesink2_lookup: FileAttachment("sourcesink2_lookup.parquet")
  // sourcesink3: FileAttachment("sourcesink3.parquet"),
  // sourcesink3_lookup: FileAttachment("sourcesink3_lookup.parquet")
})
```


::: {.column-screen-inset}


::: panel-tabset

## Source-sink model

#### Description

The key ingredients of the `source-sink model`[^1] are groups $G$ of various size with a certain number of adopters $i$ and of institution of level $\ell$. We assume that with higher levels of institutional strength, $\ell$, the institution will more effectively promote group-beneficial behavior, $\ell$$\beta$. As it gets better, each adopter in the group also gain a collective benefit [$b$]{style="color: seagreen;"}. But all of these toodily-doo perks are offset by an institutional implementation costs, [$c$]{style="color: darkred;"}, of entertaining larger groups. For instance, think of the process of unionization, promoting behaviors that are costly at individual level. When unionization becomes more successful, the unions can become ungaingly. Lastly adopters lose their behavioural trait at a rate [$\gamma$]{style="color: red;"}.

[^1]: 
@article{hebert-dufresne_source-sink_nodate,
	title = {Source-sink behavioural dynamics limit institutional evolution in a group-structured society},
	volume = {9},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.211743},
	doi = {10.1098/rsos.211743},
	number = {3},
	urldate = {2022-05-26},
	journal = {Royal Society Open Science},
	author = {Hébert-Dufresne, Laurent and Waring, Timothy M. and St-Onge, Guillaume and Niles, Meredith T. and Kati Corlew, Laura and Dube, Matthew P. and Miller, Stephanie J. and Gotelli, Nicholas J. and McGill, Brian J.}},
}


First master equation[^2]:

[^2]: A sidenote on master equations for non-physicists. The citation for master equations in the original paper is the following:

    > Hébert-Dufresne, L., Noël, P.-A., Marceau, V., Allard, A., & Dubé, L. J. (2010). Propagation dynamics on networks featuring complex topologies. Physical Review E, 82(3), 036115. https://doi.org/10.1103/PhysRevE.82.036115

    The term ''master equation'' is not mentionned once in the paper. But they do talk about "*a mean-field description used to coherently couple the dynamics of the network elements (nodes, vertices, individuals...) and their recurrent topological patterns (subgraphs, groups...)*" that yields a set of ODEs for the time evolution of the system. Another paper writen by Guillaume St-Onge et al. is a more generous in their description of master equation:

    > St-Onge, G., Thibeault, V., Allard, A., Dubé, L. J., & Hébert-Dufresne, L. (2021). Master equation analysis of mesoscopic localization in contagion dynamics on higher-order networks. Physical Review E, 103(3), 032301. https://doi.org/10.1103/PhysRevE.103.032301

    In it, section II does a great job of describing what master equations are and why they are powerful modeling tools. Relevant to this model, we learn that the size of a group is determined by drawing from a group size distribution. This is what we do in our intialization scheme above. We also learn that these 3 following papers are relevant to understand master equations:

    > Lindquist, J., Ma, J., van den Driessche, P., & Willeboordse, F. H. (2011). Effective degree network disease models. Journal of Mathematical Biology, 62(2), 143--164. https://doi.org/10.1007/s00285-010-0331-2 <br><br> Gleeson, J. P. (2011). High-Accuracy Approximation of Binary-State Dynamics on Networks. Physical Review Letters, 107(6), 068701. https://doi.org/10.1103/PhysRevLett.107.068701 <br><br> Marceau, V., Noël, P.-A., Hébert-Dufresne, L., Allard, A., & Dubé, L. J. (2010). Adaptive networks: Coevolution of disease and topology. Physical Review E, 82(3), 036116. https://doi.org/10.1103/PhysRevE.82.036116

```{=tex}
\begin{align*}
\frac{d}{dt}G_{i,\ell}^{diff} &= \ell \mathbin{\color{darkgreen}{\beta}} [(i-1) + R](n - i + 1)G_{i-1,\ell} \\
                              &- \ell\mathbin{\color{darkgreen}{\beta}} (i+R)(n-i) G_{i,\ell} \\
                              &+ \mathbin{\color{red}{\gamma}}(i+1)G_{i+1,\ell} - \mathbin{\color{red}{\gamma}} i G_{i,\ell}
\end{align*}
```
where $R = \mathbin{\color{blue}{\rho}} \sum_{i',\ell'} i'G_{i',\ell'}$ represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion [$\rho$]{style="color: blue;"}.

Second master equation:

```{=tex}
\begin{align*}
\frac{d}{dt}G_{i,\ell}^{select} &= \mathbin{\color{blue}{\rho}} [G_{i,\ell-1}(Z_\ell Z_{\ell-1}^{-1} + \mathbin{\color{midnightblue}{\mu}}) + G_{i,\ell+1}(Z\ell Z_{\ell + 1}^{-1} + \mathbin{\color{midnightblue}{\mu}})] \\
                                &-\mathbin{\color{blue}{\rho}}(Z_{\ell-1}Z_\ell^{-1} + Z_{\ell+1}^{-1} + 2\mathbin{\color{midnightblue}{\mu}})G_{i,\ell}
\end{align*}
```
where $Z_\ell = \frac{\sum_{i'} exp(\mathbin{\color{seagreen}{b}}i'- \mathbin{\color{darkred}{c}}\ell)G_{i',\ell}}{\sum_{i'}G_{i',\ell}}$. Note that we add a constant rate of transition [$\mu$]{style="color: midnightblue;"} to the selection proces.

Taken together we have the set of master equations:

$$
\frac{d}{dt}G_{i,\ell} = \frac{d}{dt}G_{i,\ell}^{diff} + \frac{d}{dt}G_{i,\ell}^{select}
$$

<details>
  <summary>Click to see the Julia code</summary>

```julia
function source_sink!(du, u, p, t)
    G, L, n = u, length(u.x), length(first(u.x))
    β, γ, ρ, b, c, μ = p
    Z, pop, R = zeros(L), zeros(L), 0.

    # Calculate mean-field coupling and observed fitness landscape
    for ℓ in 1:L
      n_adopt = collect(0:(n-1))
      Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])
      pop[ℓ]  = sum(G.x[ℓ])
      R       += sum(ρ*n_adopt .* G.x[ℓ])
      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )
    end

    for ℓ = 1:L, i = 1:n
      n_adopt, gr_size = i-1, n-1

      # Diffusion events
      du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - (ℓ-1)*β*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]

      n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ-1)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])
      n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )

      # Group selection process
      ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )
      ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )
    end
end
```
</details>

#### Playground


```{ojs}
//| panel: sidebar

// Lookup table 1
// ax_vars:     β               b    c
// fps:              γ    ρ                μ
// s_vec_idx:  ax0  fp0  fp1   ax1  ax2   fp2

sourcesink1_lookup = resdb.query("SELECT param_str as name, row_id FROM sourcesink1_lookup")

// TODO: Ideally we would like to have resdb return a lookup
sourcesink1_lookup_map = sourcesink1_lookup.reduce(function(map, obj) {
    map[obj.name] = obj.row_id;
    return map;
}, {})

lookup1 = {
  const out = {}
  out['idx2name'] = {0: "β", 1: 'γ', 2: 'ρ', 3: 'b', 4: 'c', 5: 'μ'}
  out['name2idx'] = {"β": 0, 'γ': 1, 'ρ': 2, 'b': 3, 'c': 4, 'μ': 5}
  return out
}

p1 = get_param_table(sourcesink1_lookup_map, lookup1)

av1 = ["β", "b", "c"] 
// fy1 = "α"  // choose the facet variable
fp1 = ["γ", "ρ", "μ"]

viewof s1 = Inputs.form({
  ax0: Inputs.range(p1[av1[0]]['minmax'], {step: p1[av1[0]]['s'], label: av1[0]}),
  ax1: Inputs.range(p1[av1[1]]['minmax'], {step: p1[av1[1]]['s'], label: av1[1]}),
  ax2: Inputs.range(p1[av1[2]]['minmax'], {step: p1[av1[2]]['s'], label: av1[2]}),
  fp0: Inputs.range(p1[fp1[0]]['minmax'], {step: p1[fp1[0]]['s'], label: fp1[0], value: p1[fp1[0]]['first_val']}),
  fp1: Inputs.range(p1[fp1[1]]['minmax'], {step: p1[fp1[1]]['s'], label: fp1[1], value: p1[fp1[1]]['first_val']}),
  fp2: Inputs.range(p1[fp1[2]]['minmax'], {step: p1[fp1[2]]['s'], label: fp1[2], value: p1[fp1[2]]['first_val']})
})

viewof r1 = Inputs.form({
  x: Inputs.radio(av1, {label: "x", value: av1[0]}),
  y: Inputs.radio(av1, {label: "y", value: av1[1]})
})


data = sql_data_a('sourcesink1', sourcesink1_lookup_map[`${f(s1['ax0'])}_${f(s1['fp0'])}_${f(s1['fp1'])}_${f(s1['ax1'])}_${f(s1['ax2'])}_${f(s1['fp2'])}`])
datab = sql_data_b('sourcesink1')
data_hm = get_data_heatmap(datab, lookup1, fp1, av1, r1, s1)
```


```{ojs}
//| panel: fill
html`
    <div style="display:flex; ">
      <div>${ plot_time_evo(data, "value", "reds") }</div>
      <div>${ plot_time_evo(data, "value_prop", "blues")}</div>
    </div>
`
```

```{ojs}
pd1 = phase_diagram(data_hm, r1['x'], r1['y'], 'value_prop', 'blues')
pd1d = phase_diagram(global_hm(data_hm),  r1['x'], r1['y'], 'value', 'viridis') 

html`
    <div style="display:flex; ">
    <div>
      <div>${ pd1 }</div>
      <div>${ pd1.legend('color', {label: "Level proportion →", width: 350, marginLeft: 150})
 }</div>
    </div>
    <div>
      <div>${ pd1d }</div>
      <div>${ pd1d.legend('color', {label: "Global Frequency of behavior →", width: 350, marginLeft: 150}) }</div>
    </div>
`
```

#### Takeaways

-   Frequency of behaviour in groups with different institutional strength.
-   Within groups, the frequency of cooperative behaviour follows the strength of institutions (with ℓ = 1 in light beige and ℓ = 6 in dark red).
-   Qualitatively, no institutions are possible if institutional costs are too high, and the behaviour never spreads.
-   The time dynamics of global behavioural frequency and behaviour in groups can include patterns of surge and collapse.

## Contagion model

#### Description

The key difference in that model from the last is that contagion is something to be limited by institutions of various levels. As such, $\beta$ in our model now must be negative while $\alpha$ must be positive for transmission to fall with $\ell$.

We ask ourselves to what extent the contagion is able to spread with very little $\beta$ values.

We want institutions to be able to stop contagions but contagion must exist in the first place.

```{=tex}
\begin{align*}
\frac{d}{dt}G_{i,\ell}^{\text{epi}} &= \beta {\color{red}{\ell}}^{\color{red}{-\alpha}} [(i-1) + R](n - i + 1)G_{i-1,\ell} \\
                              &- \beta {\color{red}{\ell}}^{\color{red}{-\alpha}} (i+R)(n-i) G_{i,\ell} \\
                              &+ \gamma(i+1)G_{i+1,\ell} - \mathbin{\gamma} i G_{i,\ell}
\end{align*}
```
where $R = \mathbin{\rho} \sum_{i',\ell'} i'G_{i',\ell'}$ represents the global diffusion of behaviors and primes denote variable over which we sum to calculate global quantity. The sum over adopters at each level weighted by global behavioural diffusion $\rho$.

<details>
  <summary>Click to see the Julia code</summary>

``` julia
function source_sink2!(du, u, p, t)
    G, L, n = u, length(u.x), length(first(u.x))
    β, α, γ, ρ, b, c, μ = p
    Z, pop, R = zeros(L), zeros(L), 0.

    # Calculate mean-field coupling and observed fitness landscape
    for ℓ in 1:L
        n_adopt = collect(0:(n-1))
        Z[ℓ]    = sum(exp.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ]) 
        pop[ℓ]  = sum(G.x[ℓ])
        R      += sum(ρ * n_adopt .* G.x[ℓ]) 
        pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] ) 
      end
      
      for ℓ = 1:L, i = 1:n
        n_adopt, gr_size = i-1, n-1
        # Diffusion events
        du.x[ℓ][i] = -γ*n_adopt*G.x[ℓ][i] - β*(ℓ^-α)*(n_adopt+R)*(gr_size-n_adopt)*G.x[ℓ][i]
        n_adopt > 0 && ( du.x[ℓ][i] += β*(ℓ^-α)*(n_adopt-1+R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1])
        n_adopt < gr_size && ( du.x[ℓ][i] +=  γ*(n_adopt+1)*G.x[ℓ][i+1] )
        # Group selection process
        ℓ > 1 && ( du.x[ℓ][i] += ρ*G.x[ℓ-1][i]*(Z[ℓ] / Z[ℓ-1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ-1] / Z[ℓ]+μ) )
        ℓ < L && ( du.x[ℓ][i] += ρ*G.x[ℓ+1][i]*(Z[ℓ] / Z[ℓ+1] + μ) - ρ*G.x[ℓ][i]*(Z[ℓ+1] / Z[ℓ]+μ) )
      end
end
```
</details>

<details>
  <summary>Click to see the parameters definition</summary>

 - `β`: Spreading rate from non-adopter to adopter beta
 - `ξ`: Simple-complex contagion parameter
 - `α`: Negative benefits alpha
 - `γ`: Recovery rate gamma, i.e rate at which adopters loose  behavioral trait
 - `ρ`: rate between groups to  spread the contagion
 - `η`: rate between groups to    spread the institution level.
 - `b`: Group benefits b
 - `c`: Institutional cost c
 - `μ`: Noise u

</details>

#### Playground

```{ojs}
//| panel: sidebar

// Lookup table 2
// param_str:   β,   ξ,   α,   γ,   ρ,   η,   b,   c    μ
// param_grid: 
// ax_vars:    
// fps:        
// s_vec_idx:  

sourcesink2_lookup = resdb.query("SELECT param_str as name, row_id FROM sourcesink2_lookup")

// TODO: Ideally we would like to have resdb return a lookup
sourcesink2_lookup_map = sourcesink2_lookup.reduce(function(map, obj) {
    map[obj.name] = obj.row_id;
    return map;
}, {})

lookup2 = {
  const out = {}
  out['idx2name'] = {0: 'β', 1: 'ξ', 2: 'α', 3: 'γ', 4: 'ρ', 5: 'η', 6: 'b', 7: 'c', 8:'μ'}
  out['name2idx'] = {'β': 0, 'ξ': 1, 'α': 2, 'γ': 3, 'ρ': 4, 'η': 5, 'b': 6, 'c': 7, 'μ': 8}
  return out
}

p2 = get_param_table(sourcesink2_lookup_map, lookup2)

ax_vars2 = ["β", "ρ", "η"] // choose the x,y,z axis, i.e. params to vary
fy2 = "α"  // choose the facet variable
fp2 = ["ξ", "α", "γ", "b", "c", "μ"]


viewof r2 = Inputs.form({
  x: Inputs.radio(ax_vars2, {label: "x", value: ax_vars2[0]}),
  y: Inputs.radio(ax_vars2, {label: "y", value: ax_vars2[1]})
})

viewof s2 = Inputs.form({
  ax0: Inputs.range(p2[ax_vars2[0]]['minmax'], {step: p2[ax_vars2[0]]['s'], label: ax_vars2[0]}),
  ax1: Inputs.range(p2[ax_vars2[1]]['minmax'], {step: p2[ax_vars2[1]]['s'], label: ax_vars2[1]}),
  ax2: Inputs.range(p2[ax_vars2[2]]['minmax'], {step: p2[ax_vars2[2]]['s'], label: ax_vars2[2]}),
  fp0: Inputs.range(p2[fp2[0]]['minmax'], {step: p2[fp2[0]]['s'], label: fp2[0], value: p2[fp2[0]]['first_val']}),
  fp1: Inputs.range(p2[fy2]['minmax'], {step: p2[fy2]['s'], label: fy2, value: p2[fy2]['first_val']}),
  fp2: Inputs.range(p2[fp2[2]]['minmax'], {step: p2[fp2[2]]['s'], label: fp2[2], value: p2[fp2[2]]['first_val']}),
  fp3: Inputs.range(p2[fp2[3]]['minmax'], {step: p2[fp2[3]]['s'], label: fp2[3], value: p2[fp2[3]]['first_val']}),
  fp4: Inputs.range(p2[fp2[4]]['minmax'], {step: p2[fp2[4]]['s'], label: fp2[4], value: p2[fp2[4]]['first_val']}),
  fp5: Inputs.range(p2[fp2[5]]['minmax'], {step: p2[fp2[5]]['s'], label: fp2[5], value: p2[fp2[5]]['first_val']}),
})


data2 = sql_data_a('sourcesink2', sourcesink2_lookup_map[`${f(s2['ax0'])}_${f(s2['fp0'])}_${f(s2['fp1'])}_${f(s2['fp2'])}_${f(s2['ax1'])}_${f(s2['ax2'])}_${f(s2['fp3'])}_${f(s2['fp4'])}_${f(s2['fp5'])}`])
data2b = sql_data_b("sourcesink2")
data_hm2 = get_data_heatmap(data2b, lookup2, fp2, ax_vars2, r2, s2, fy2)
```

```{ojs}
//| panel: fill
html`
    <div style="display:flex; ">
      <div>${ plot_time_evo(data2, "value", "reds") }</div>
      <div>${ plot_time_evo(data2, "value_prop", "blues")}</div>
    </div>
`
```


```{ojs}
pd2 = phase_diagram(data_hm2, r2['x'], r2['y'], 'value_prop', "blues", fy2)
pd2d = phase_diagram(global_hm(data_hm2),  r2['x'], r2['y'], 'value', 'viridis') 

html`
    <div style="display:flex; ">
    <div>
      <div>${ pd2 }</div>
      <div>${ pd2.legend('color', {label: "Level proportion →", width: 350, marginLeft: 150})
 }</div>
    </div>
    <div>
      <div>${ pd2d }</div>
      <div>${ pd2d.legend('color', {label: "Global Frequency of behavior →", width: 350, marginLeft: 150}) }</div>
    </div>
`
```


## Game-theoretic model

#### Description

UPDATE DESCRIPTION. WHY DO WE CARE. IS IT USEFUL FOR POLICY?! WHO AM I?

<details>
  <summary>Click to see the Julia code</summary>

```julia
function source_sink3!(du, u, p, t)
  G, L, n = u, lengts(u.x), lengts(u.x[1])
  β, γ, ρ, b, c, μ, δ = p # δ = 1 (δ = 0): (no) resource requirement to upgrade institution
  Z, pop, R = zeros(L), zeros(L), 0.

  # Calculate mean-field coupling and observed fitness landscape
    for ℓ in 1:L
      n_adopt = collect(0:(n-1))
      Z[ℓ]    = sum(f.(b*n_adopt .- c*(ℓ-1)) .* G.x[ℓ])
      pop[ℓ]  = sum(G.x[ℓ])
      R      += sum(n_adopt .* G.x[ℓ]) # Global diffusion
      pop[ℓ] > 0.0 && ( Z[ℓ] /= pop[ℓ] )
    end

    for ℓ = 1:L, i = 1:n
      n_adopt, gr_size = i-1, n-1
      # Individual selection process
      du.x[ℓ][i] = -n_adopt*f(1-s(ℓ))*G.x[ℓ][i] - (gr_size-n_adopt)*f(s(ℓ)-1)*G.x[ℓ][i]
      du.x[ℓ][i] += - n_adopt*(gr_size-n_adopt)*(β+γ)*G.x[ℓ][i] - ρ*(gr_size-n_adopt)*β*R*G.x[ℓ][i] - ρ*n_adopt*γ*(gr_size-R)*G.x[ℓ][i]
      n_adopt > 0 && ( du.x[ℓ][i] += (gr_size-n_adopt+1)*f(s(ℓ)-1)*G.x[ℓ][i-1] + β*(n_adopt-1+ρ*R)*(gr_size-n_adopt+1)*G.x[ℓ][i-1] )
      n_adopt < gr_size && ( du.x[ℓ][i] += (n_adopt+1)*f(1-s(ℓ))*G.x[ℓ][i+1] + γ*(gr_size-n_adopt-1+ρ*(gr_size-R))*(n_adopt+1)*G.x[ℓ][i+1] )
      # Group selection process
      ℓ > 1 && ( du.x[ℓ][i] += (f(b*n_adopt-c*(ℓ-1))^δ)*(μ+ρ*Z[ℓ]/Z[ℓ-1])*G.x[ℓ-1][i] - (μ*(f(c*(ℓ-1)-b*n_adopt)^δ)+ρ*(f(b*n_adopt-c*(ℓ-2))^δ)*Z[ℓ-1]/Z[ℓ])*G.x[ℓ][i] )
      ℓ < L && ( du.x[ℓ][i] += (μ*(f(c*ℓ-b*n_adopt)^δ)+ρ*(f(b*n_adopt-c*(ℓ-1))^δ)*Z[ℓ]/Z[ℓ+1])*G.x[ℓ+1][i] - (f(b*n_adopt-c*ℓ)^δ)*(μ+ρ*Z[ℓ+1]/Z[ℓ])*G.x[ℓ][i] )
    end
end
```
</details>

#### Playground


```{ojs sidebar model 3}
//| panel: sidebar

// Lookup table 3
// param_str:   β,   γ,   ρ,   b,   c,   μ,   δ,   α
// param_grid:  β    γ,   ρ,   b,   1., 0.2,  1.,  α
// ax_vars:     β,        ρ,                       α
// fps:              γ,        b,   c,   μ,   δ
// s_vec_idx:  ax0, fp0, ax1, fp1, fp2, fp3, fp4, ax2

// sourcesink3_lookup = resdb.query("SELECT param_str as name, row_id FROM sourcesink3_lookup")

// TODO: Ideally we would like to have resdb return a lookup
sourcesink3_lookup_map = sourcesink3_lookup.reduce(function(map, obj) {
    map[obj.name] = obj.row_id;
    return map;
}, {})

lookup3 = {
  const out = {}
  out['idx2name'] = {0: "β", 1: 'γ', 2: 'ρ', 3: 'b', 4: 'c', 5: 'μ', 6: 'δ', 7: 'α'}
  out['name2idx'] = {"β": 0, 'γ':1, 'ρ': 2, 'b': 3, 'c': 4, 'μ': 5, 'δ': 6, 'α': 7}
  return out
}

p3 = get_param_table(sourcesink3_lookup_map, lookup3)

av3 = ["β", "ρ", 'α']           // ax vars
fy3 = "δ"                       // facet y var
fp3 = ["γ", "b", "c", "μ", fy3] // fixed param vars

// sliders
viewof s3 = Inputs.form({
  ax0: Inputs.range(p3[av3[0]]['minmax'], {step: p3[av3[0]]['s'], label: av3[0]}),
  ax1: Inputs.range(p3[av3[1]]['minmax'], {step: p3[av3[1]]['s'], label: av3[1]}),
  ax2: Inputs.range(p3[av3[2]]['minmax'], {step: p3[av3[2]]['s'], label: av3[2]}),
  fp0: Inputs.range(p3[fp3[0]]['minmax'], {step: p3[fp3[0]]['s'], label: fp3[0], value: p3[fp3[0]]['first_val']}),
  fp1: Inputs.range(p3[fp3[1]]['minmax'], {step: p3[fp3[1]]['s'], label: fp3[1], value: p3[fp3[1]]['first_val']}),
  fp2: Inputs.range(p3[fp3[2]]['minmax'], {step: p3[fp3[2]]['s'], label: fp3[2], value: p3[fp3[2]]['first_val'], disabled: true}),
  fp3: Inputs.range(p3[fp3[3]]['minmax'], {step: p3[fp3[3]]['s'], label: fp3[3], value: p3[fp3[3]]['first_val'], disabled: true}),
  fp4: Inputs.range(p3[fp3[4]]['minmax'], {step: p3[fp3[4]]['s'], label: fp3[4], value: p3[fp3[4]]['first_val'], disabled: true})
})

// radios
viewof r3 = Inputs.form({
  x: Inputs.radio(av3, {label: "x", value: av3[0]}),
  y: Inputs.radio(av3, {label: "y", value: av3[1]})
})


// data3a = sql_data_a('sourcesink3', sourcesink3_lookup_map[`${f(s3["ax0"])}_${f(s3["fp0"])}_${f(s3["ax1"])}_${f(s3["fp1"])}_${f(s3["fp2"])}_${f(s3["fp3"])}_${f(s3["fp4"])}_${f(s3["ax2"])}`])
// data3a = sql_data_a('sourcesink3', sourcesink3_lookup_map[`0.0_0.0_0.0_0.2_1.0_0.1_1.0_0.14`])
// data3b = sql_data_b("sourcesink3")
// data_hm3 = get_data_heatmap(data3b, lookup3, fp3, av3, r3, s3, fy3)
```

```{ojs dashboard model 3 - time evo}
//| panel: fill
html`
    <div style="display:flex; ">
      <div>${ plot_time_evo(data3a, "value", "reds") }</div>
      <div>${ plot_time_evo(data3a, "value_prop", "blues")}</div>
    </div>
`
```

```{ojs dashboard model 3 - phase diagrams}
pd3 = phase_diagram(data_hm3,  r3['x'], r3['y'], 'value_prop', 'blues', fy3)
pd3d = phase_diagram(global_hm(data_hm3),  r3['x'], r3['y'], 'value', 'viridis') 
html`
    <div style="display:flex; ">
    <div>
      <div>${ pd3 }</div>
      <div>${ pd3.legend('color', {label: "Level proportion →", width: 350, marginLeft: 150}) }</div>
    </div>
    <div>
      <div>${ pd3d }</div>
      <div>${ pd3d.legend('color', {label: "Global Frequency of behavior →", width: 350, marginLeft: 150}) }</div>
    </div>
`
```

:::

::: {.callout-note collapse="true"}
## Model 1 Sketch

![](sourcesink_sketch.jpg)
:::
:::

```{ojs helpers}
function sql_data_a(model, name) {
    return resdb.query(`
      SELECT timestep::INT as timestep, L::INT as L, value, value_prop
      FROM ${model}
      WHERE
      row_id = '${name}'
    `)
}

function sql_data_b(model) {
    return resdb.query(`
      WITH tmp as (
          SELECT row_id, L, MAX(timestep::INT) as timestep
          FROM ${model}
          GROUP BY row_id, L
      )
      SELECT s.value, s.L::INT as L, s.value_prop, ss.param_str as name
      FROM ${model} s
      JOIN tmp
      ON s.row_id = tmp.row_id AND s.L = tmp.L AND s.timestep = tmp.timestep
      JOIN ${model}_lookup ss
      ON s.row_id = ss.row_id
      ORDER BY (s.row_id, s.L)
  `)
}


function get_fixed_params(param_table, ax_vars, fx) {
  const all_params = [...Object.keys(param_table)]
  const varying_params = typeof fx !== undefined ? new Set(ax_vars) : new Set(ax_vars.concat(fx))
  const diff_params = new Set(all_params.filter((x) => !varying_params.has(x)))
  return Array.from(diff_params)
}

f = (x) => Number.isInteger(x) ? x.toPrecision(2) : x

// Extract the step from a list of values for a parameter
s = (p,i) => { 
    const unique_vals = Array.from(new Set(p.map(d => parseFloat(d[i])))).sort((a,b) => a - b)
    const out = []
    for (let i=1; i < unique_vals.length; i++ ) {
      out.push(+(unique_vals[i]-unique_vals[i-1]).toPrecision(2))
    } // return whatev if length is zero
    return out.length === 0 ? 0.1 : out[0]
}

minmax = (p, i) => d3.extent(p.map(d => parseFloat(d[i])))

// Param table where each key is a parameter, and values 
// are list of values relevant to 
// model: resdb output for a specific model
// lookup: { [0: param1, 1: param2, ...] }
function get_param_table(model_lookup, param_lookup) {
    
  const p = Object.keys(model_lookup).map(d => d.split("_")) 
  
  const param_table = {}
  const first_line_param = p[0]
  for ( let i=0; i < first_line_param.length; i++ ) {
    param_table[param_lookup['idx2name'][i]] = { 
      's': s(p,i), 'first_val': first_line_param[i], 'minmax': minmax(p,i) 
      }
  }
  return param_table
}

// To get heatmap data, we need
//   data: data from resdb join `name` and `L`
//   ax_vars: variables we want as x,y,z
//   fx: variable to facet
//   fp: other vars
//   sliders: set of sliders
function get_data_heatmap(data, lookup, fp, ax_vars, radios, sliders, fx) {
  const dat_hm = [];
  
  for (let i=0; i < data.length; i++) { 
    
    const p_split = data[i].name.split('_')
    
    const vs = {} // dictionary containing all the values of selected parameters 

    // Grab the chosen axis0/x, axis1/y, axis2/z
    const [ax0, ax1, ax2] = ax_vars
    vs[ax0] = parseFloat(p_split[lookup['name2idx'][ax0]])
    vs[ax1] = parseFloat(p_split[lookup['name2idx'][ax1]])
    vs[ax2] = parseFloat(p_split[lookup['name2idx'][ax2]])

    // Grab the Fixed parameters
    for (let i=0; i < fp.length; i++) {
      vs[fp[i]] = parseFloat(p_split[lookup['name2idx'][fp[i]]])
    }
    
    // Grab the radios, which will be 2 of the 3 axis vars. 
    // The other other one we'll be the value of our heatmap.
    // This is where we need to know the actual param_name.
    const p1 = parseFloat(p_split[lookup['name2idx'][radios['x']]])
    const p2 = parseFloat(p_split[lookup['name2idx'][radios['y']]])
    const hm_vals_i = {
      'L': data[i].L,
      'fx' : typeof fx !== undefined ? null : p_split[lookup['name2idx'][fx]], 
      'param1': p1,
      'param2': p2,
      'param_str': `${p1}/${p2}`, // We need a way to groupby (p1,p2) for `global_hm()`
      'value': data[i].value,
      'value_prop': data[i].value_prop
    }

    if (vs[fp[0]] === sliders['fp0'] && vs[fp[1]] === sliders['fp1'] && vs[fp[2]] === sliders['fp2'] && vs[fp[3]] == sliders['fp3'] && vs[fp[4]] == sliders['fp4']) {

        // if ax1 == x && ax2 ==y, then ax0 == z
        if (radios['x'] == ax1 && radios['y'] == ax2 && vs[ax0] == sliders['ax0']) {
             dat_hm.push(hm_vals_i)
        } else if (radios['x'] == ax0 && radios['y'] == ax2 && vs[ax1] == sliders['ax1']) {
             dat_hm.push(hm_vals_i)
        } else if (radios['x'] == ax0 && radios['y'] == ax1 && vs[ax2] == sliders['ax2']) {
             dat_hm.push(hm_vals_i)
        }
    }
  }
  return dat_hm
}

function global_hm(d){
  return d3.flatRollup(d, v => d3.sum(v, d => d.value * d.value_prop), d => d.param_str)
           .map(currentElement => ({
             'param1': parseFloat(currentElement[0].split('/')[0]),
             'param2': parseFloat(currentElement[0].split('/')[1]),
             'value': currentElement[1],
             'L': 1
          }))
}


function plot_time_evo(d, y_vals, pal) {
  const global_mean = d3.rollup(d, v => d3.sum(v, d => d.value * d.value_prop), d => d.timestep)

  return Plot.plot({
    x: {type:"log"},
    marginLeft: 50,
    color: { 
      scheme: pal, 
      type: "ordinal", 
      range: [0.3, 1],
      legend: true 
    },
    marks: [
      Plot.lineY(Array.from(global_mean.values()), {
        strokeDasharray: "5,3", opacity: pal == 'blues' ? 0 : 1.
        }),
      Plot.line(
        d, {
          x: 'timestep', y: y_vals, stroke: "L"
          }),
      Plot.dot(
        d, {
          x: 'timestep', y: y_vals, stroke: "L"
          })
    ]
  })
}

function phase_diagram(d, x, y, z, pal, fy) {
  return PlotDev.plot({
    width: 1200,
    height: 600,
    color: {
      type: "linear",
      scheme: pal
    },
    x: { label: x },
    y: { label: y },
    fy: { label: fy },
    facet: { 
      data: d, 
      x: "L", 
      y: typeof fy !== undefined ? 'fx' : null 
    },
    marks: [
      PlotDev.raster(d, {
        x: "param1",
        y: "param2",
        fill: z,
        interpolate: "nearest"
      }),
    ]
  })
}
```


```{ojs}
PlotDev = await import("https://esm.sh/@observablehq/plot");
```
